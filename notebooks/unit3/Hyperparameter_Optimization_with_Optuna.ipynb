{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVjsDhlvg1CWtWwQH0bIHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wengti/Reinforcement-Learning-Tutorial-/blob/main/notebooks/unit3/Hyperparameter_Optimization_with_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "* The following notebook focuses on applying Optuna in Reinforcement Learning.\n",
        "* Source / Reference of this notebook: https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb#scrollTo=4UU17YpjymPr\n",
        "* To study the application of Optuna in Deep Learning, refer to: https://www.geeksforgeeks.org/hyperparameter-tuning-with-optuna-in-pytorch/\n"
      ],
      "metadata": {
        "id": "0atzJ01M2R1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick guides on the step needed.\n",
        "\n",
        "1. Define a config.\n",
        "2. Define a search space or a function that returns the parameters that define the models.\n",
        "3. Define an objective score function that will return the objective score function for the sampled set of hyperparameter.\n",
        "4. Create a optimization loop\n",
        "  - For each trial:\n",
        "    - a) sample a hyperparameter\n",
        "    - b) Use the hyperparameter to train. At intervals, evaluate the performance of the models and decided if to prune this trial."
      ],
      "metadata": {
        "id": "eVTTYdLGiH7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Library Installation and Import"
      ],
      "metadata": {
        "id": "FfIEjXnu8n__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xzoskFD02LW2",
        "outputId": "93dbdaa5-8340-41e6-c10f-e684e48e407a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "# Install optuna library\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Stable Baseline 3\n",
        "!pip install stable-baselines3==2.0.0a5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AHCK3ANyc3w3",
        "outputId": "5716574c-9548-4bc0-afbc-76a3b60a2701"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3==2.0.0a5\n",
            "  Downloading stable_baselines3-2.0.0a5-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting gymnasium==0.28.1 (from stable-baselines3==2.0.0a5)\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (3.10.0)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->stable-baselines3==2.0.0a5) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.0.0a5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.0.0a5) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a5) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a5) (3.0.2)\n",
            "Downloading stable_baselines3-2.0.0a5-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jax-jumpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gymnasium, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.28.1 jax-jumpy-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.0.0a5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gymnasium\n",
        "\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZH7FgnjqVvX",
        "outputId": "2c6b0d82-f9d4-47fa-fae3-ee3f61788c6f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Using cached swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\n",
            "Using cached swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.3.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.3 (from gymnasium[box2d])\n",
            "  Using cached pygame-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.3.1)\n",
            "Using cached pygame-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379371 sha256=c83611c5b3ce9ef831a8a0d95b62d4f87411120a87123b329864aa0fff59be42\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed box2d-py-2.3.5 pygame-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "\n",
        "\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.a2c import A2C\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "import gymnasium as gym\n",
        "\n",
        "import torch as th\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "wF0YE3gk8f5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO: Tune a A2C agent that plays CartPole-v1"
      ],
      "metadata": {
        "id": "GM6tS6uoj5I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create config / key parameters\n",
        "\n",
        "* Terminology:\n",
        "1. `TRIALS`  - Each `TRIAL` is initiated with different sampled set of hyperparameter. If needed, multiple `JOBS` can be initiated in parallel for each trial. Each `TRIAL` will involve training the agent / model for `N_TIMESTEPS`.\n",
        "\n",
        "2. `EVAL_EPISODES` - During the training that last for `N_TIMESTEPS`, at an interval of `EVAL_FREQ`, evaluation will be performed. For each evaluation, `N_EVAL_EPISODES` of evaluation episodes will be sampled and reviewed. This may help the scheduler to decide whether to prune early.\n"
      ],
      "metadata": {
        "id": "6Fyd02Q48I6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "# Hyperparameter Optimization Loop\n",
        "N_TRIALS = 100 # Maximum number of trials during Hyperparameter Optimization Loop\n",
        "N_JOBS = 1 # Number of parallel jobs to run during each trials in Hyperparameter Optimization Loop\n",
        "N_STARTUP_TRIALS = 5 # Number of trials to perform random sampling (without relying on sampler) during the Hypeparameter Optimization Loop (To create the initial database)\n",
        "TIMEOUT = int(60*15) # Maximum number of times (in seconds) the entire loop is allowed up to.\n",
        "\n",
        "# Evaluation Parameter for each set of hyperparameter\n",
        "N_TIMESTEPS = int(2e4) # Training budget - Number of time steps in one FULL TRIAL for each set of hyperparameter.\n",
        "N_EVALUATIONS = 2 # Number of intermediate evaluations performed in one FULL TRIAL for each set of hyperparameter.\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS) # Step interval for each intermediate evaluations during one FULL TRIAL.\n",
        "N_EVAL_EPISODES = 10 # Number of episodes to be sampled for each evaluation.\n",
        "\n",
        "\n",
        "# Environment Parameter\n",
        "N_EVAL_ENVS = 5 # Number of environments used in parallel during evaluation.\n",
        "\n",
        "ENV_ID = \"CartPole-v1\" # ID of the environments, to be initiated with gym.make()\n",
        "\n",
        "# Algorithm Parameter\n",
        "ALGO_NAME = \"A2C\""
      ],
      "metadata": {
        "id": "mP4SS2Lr89QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define the search space"
      ],
      "metadata": {
        "id": "C1SySDFDA4RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_a2c_params(trial):\n",
        "\n",
        "  \"\"\"\n",
        "  Sample a set of hyperparameter to be trial'd.\n",
        "\n",
        "  Args:\n",
        "    trial (optuna.Trial) : An Optuna trial object.\n",
        "\n",
        "  Returns:\n",
        "    params (dict): The hyperparameters to be trial'd. Its key matches the keywords used in defining models.\n",
        "  \"\"\"\n",
        "\n",
        "  # Refer to this link: https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html#example\n",
        "  # To study the hyperparameter to be updated.\n",
        "\n",
        "  ###################\n",
        "  # Discount factor #\n",
        "  ###################\n",
        "  # suggest.float -> sample from a continuos space (float)\n",
        "  # \"gamma\" - name (to be showcased in the final plot)\n",
        "  # log - means sample from log space\n",
        "  gamma = 1 - trial.suggest_float(\"one_minus_gamma\", 0.0001, 0.1, log = True)\n",
        "\n",
        "  # Create another attribute to store the actual gamma value\n",
        "  trial.set_user_attr(\"gamma\", gamma)\n",
        "\n",
        "  #######################################\n",
        "  # Maximum value for gradient clipping #\n",
        "  #######################################\n",
        "  max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 0.5, log=True)\n",
        "\n",
        "  ##########################################################\n",
        "  # Number of steps to run for each environment per update #\n",
        "  ##########################################################\n",
        "  n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "  # Create another attribute to store the actual n_steps\n",
        "  trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "  #################\n",
        "  # Learning_rate #\n",
        "  #################\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n",
        "\n",
        "  ########################\n",
        "  # Network architecture #\n",
        "  ########################\n",
        "  # https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html#a2c-policies\n",
        "\n",
        "  net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
        "\n",
        "  # The net_arch expects a list, that is why it is wrapped in a list\n",
        "  net_arch = [{\"pi\": [64], \"vf\": [64]} if net_arch == 'tiny' \\\n",
        "              else {\"pi\" : [64, 64], \"vf\" : [64, 64]}]\n",
        "\n",
        "  #######################\n",
        "  # Activation Function #\n",
        "  #######################\n",
        "  activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
        "\n",
        "  activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "\n",
        "\n",
        "  # Note: The key used in this dictionary match the key used in defining the models\n",
        "  # Therefore, the naming convention must be followed.\n",
        "  params = {\"n_steps\": n_steps,\n",
        "          \"gamma\": gamma,\n",
        "          \"learning_rate\": learning_rate,\n",
        "          \"max_grad_norm\": max_grad_norm,\n",
        "          \"policy_kwargs\": {\"net_arch\": net_arch,\n",
        "                            \"activation_fn\": activation_fn}}\n",
        "\n",
        "  return params\n"
      ],
      "metadata": {
        "id": "OVOJxJJfA6Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define objective"
      ],
      "metadata": {
        "id": "ZvXBgvUdKE50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A custom callback function is defined to report the results of periodic evaluations."
      ],
      "metadata": {
        "id": "oluw-HebUls9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrialEvalCallback(EvalCallback):\n",
        "\n",
        "  \"\"\"\n",
        "  Callback used for evaluating and reporting a trial.\n",
        "\n",
        "  Args:\n",
        "    eval_env (gym.env): An evaluation environment.\n",
        "    trial (Optuna.trial): An Optuna trial object.\n",
        "    n_eval_episodes (int): Number of evaluation episodes for each evaluation.\n",
        "    eval_freq (int): Step interval for an intermediate evaluation in each trial.\n",
        "    deterministic (boolean): Whether the evaluation should use stochastic or deterministic policy.\n",
        "    verbose (int):\n",
        "\n",
        "  Returns:\n",
        "    out (boolean):\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose = 0):\n",
        "\n",
        "    super().__init__(eval_env = eval_env, n_eval_episodes = n_eval_episodes,\n",
        "                    eval_freq = eval_freq, deterministic = deterministic,\n",
        "                    verbose = verbose)\n",
        "    self.trial = trial\n",
        "    self.eval_idx = 0\n",
        "    self.is_pruned = False\n",
        "\n",
        "  def _on_step(self):\n",
        "    if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "      super()._on_step()\n",
        "      self.eval_idx += 1\n",
        "\n",
        "      # Send report to optuna\n",
        "      self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "\n",
        "      # Prune trial if needed\n",
        "      if self.trial.should_prune():\n",
        "        self.is_pruned = True\n",
        "        return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "n8C4rikaKEtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The true objective function."
      ],
      "metadata": {
        "id": "pBqdwtvnUs0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "  \"\"\"\n",
        "  A function that returns the objective score that decides the quality of a set of hyperparameter.\n",
        "\n",
        "  Args:\n",
        "    trial (optuna.Trial): An Optuna trial object.\n",
        "\n",
        "  Returns:\n",
        "    objective_score (float): The score that represents the quality of this set of hyperparameter.\n",
        "  \"\"\"\n",
        "\n",
        "  # Creat the default keyword arguments (those that wasnt defined in the hyperparameter sampling function)\n",
        "  kwargs = {\"policy\": \"MlpPolicy\",\n",
        "            \"env\": ENV_ID}\n",
        "\n",
        "  # Update with the inclusion of the sampled hyperparameter\n",
        "  kwargs.update(sample_a2c_params(trial))\n",
        "\n",
        "  # Create a model using the sampled hyperparameter\n",
        "  model = A2C(**kwargs)\n",
        "\n",
        "  # Create the environments\n",
        "  eval_envs = make_vec_env(env_id = ENV_ID,\n",
        "                           n_envs = N_EVAL_ENVS)\n",
        "\n",
        "  # Create the call back for reporting evaluation results\n",
        "  eval_callback = TrialEvalCallback(eval_env = eval_envs,\n",
        "                                    trial = trial,\n",
        "                                    n_eval_episodes = N_EVAL_EPISODES,\n",
        "                                    eval_freq = EVAL_FREQ,\n",
        "                                    deterministic = True)\n",
        "\n",
        "  nan_encountered = False\n",
        "  try:\n",
        "    model.learn(N_TIMESTEPS, callback = eval_callback)\n",
        "  except AssertionError as e:\n",
        "    # Sometimes, randomly sampled error can lead to NaN\n",
        "    print(e)\n",
        "    nan_encountered = True\n",
        "  finally:\n",
        "    # At the end of training or if error is encountered\n",
        "    # Free Memory\n",
        "    model.env.close()\n",
        "    eval_envs.close()\n",
        "\n",
        "  # Inform the optimizer that a non-valid hyperparameter is sampled\n",
        "  if nan_encountered:\n",
        "    return float('nan')\n",
        "\n",
        "  if eval_callback.is_pruned:\n",
        "    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return eval_callback.last_mean_reward\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WcvtN9sCUsdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Define Hyperparameter Optimization Loop"
      ],
      "metadata": {
        "id": "nBr6bebTYASV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set PyTorch num threads to 1 for faster training\n",
        "# Parallel environement will demand heavy use of CPU.\n",
        "# Therefore, this line limits to the usage of cpu for PyTorch to be only 1 line.\n",
        "th.set_num_threads(1)\n",
        "\n",
        "# Select a sampler\n",
        "# https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html\n",
        "# n_startup_trials -> Number of trials at the beginning that sample a set of hyperparameter randomly instead of using the algorithm\n",
        "# This allows the creation of initial database.\n",
        "sampler = TPESampler(n_startup_trials = N_STARTUP_TRIALS)\n",
        "\n",
        "# Select a scheduler / pruner\n",
        "# https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html\n",
        "# n_startup_trials -> Pruning is disabaled at the beginning for this many trials for initial database creation.\n",
        "# n_warmup_steps -> Number of steps in each trial that disable the pruning.\n",
        "pruner = MedianPruner(n_startup_trials = N_STARTUP_TRIALS,\n",
        "                      n_warmup_steps = N_TIMESTEPS // 3)\n",
        "\n",
        "# Create a study for Hyperparameter Optimization\n",
        "# https://optuna.readthedocs.io/en/stable/reference/generated/optuna.create_study.html\n",
        "study = optuna.create_study(sampler = sampler,\n",
        "                            pruner = pruner,\n",
        "                            direction = \"maximize\")\n",
        "\n",
        "try:\n",
        "  # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize\n",
        "  study.optimize(objective,\n",
        "                 n_trials = N_TRIALS,\n",
        "                 timeout = TIMEOUT,\n",
        "                 n_jobs = N_JOBS)\n",
        "except KeyboardInterrupt:\n",
        "  pass\n",
        "\n",
        "# Print the meta info for the hyperparameter optimization process\n",
        "print(f\"Number of finished trials: {len(study.trials)}\")\n",
        "trial = study.best_trial\n",
        "print(f\"Best trial: {trial.value}\")\n",
        "\n",
        "print(\"Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"User Attributes: \")\n",
        "for key, value in trial.user_attrs.items():\n",
        "  print(f\"  {key}: {value}\")\n",
        "\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(f\"study_result_{ALGO_NAME}_{ENV_ID}.csv\")\n",
        "\n",
        "# Show plot\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hft4XM_EYAhl",
        "outputId": "a30e55b2-46e4-46ee-c48e-e4e7cd4b82dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-12 09:35:47,739] A new study created in memory with name: no-name-813ee568-ff50-443a-8067-43acc1197b30\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:460: UserWarning:\n",
            "\n",
            "As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "\n",
            "[I 2025-06-12 09:36:19,525] Trial 0 finished with value: 9.2 and parameters: {'one_minus_gamma': 0.012924707618275728, 'max_grad_norm': 0.34796692788707256, 'exponent_n_steps': 5, 'learning_rate': 0.02729744524579956, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 9.2.\n",
            "[I 2025-06-12 09:36:49,605] Trial 1 finished with value: 9.2 and parameters: {'one_minus_gamma': 0.038723746654246494, 'max_grad_norm': 0.31201984520850595, 'exponent_n_steps': 5, 'learning_rate': 0.9681078693342838, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 9.2.\n",
            "[I 2025-06-12 09:37:18,442] Trial 2 finished with value: 9.3 and parameters: {'one_minus_gamma': 0.002021039321497278, 'max_grad_norm': 0.4573768403784507, 'exponent_n_steps': 9, 'learning_rate': 0.033465645144241316, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 2 with value: 9.3.\n",
            "[I 2025-06-12 09:37:45,863] Trial 3 finished with value: 91.7 and parameters: {'one_minus_gamma': 0.0008731735219335531, 'max_grad_norm': 0.42242142489836154, 'exponent_n_steps': 10, 'learning_rate': 0.0001377051820576272, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 3 with value: 91.7.\n",
            "[I 2025-06-12 09:38:14,860] Trial 4 finished with value: 116.7 and parameters: {'one_minus_gamma': 0.0012304139554903581, 'max_grad_norm': 0.34187386202680636, 'exponent_n_steps': 7, 'learning_rate': 4.943762839521544e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 4 with value: 116.7.\n",
            "[I 2025-06-12 09:38:43,782] Trial 5 finished with value: 122.5 and parameters: {'one_minus_gamma': 0.0001086993609073862, 'max_grad_norm': 0.3664679902505558, 'exponent_n_steps': 7, 'learning_rate': 1.0931118938412466e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 5 with value: 122.5.\n",
            "[I 2025-06-12 09:39:24,908] Trial 6 finished with value: 84.9 and parameters: {'one_minus_gamma': 0.000103139578231042, 'max_grad_norm': 0.39016124526574136, 'exponent_n_steps': 3, 'learning_rate': 1.1655477426432292e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 5 with value: 122.5.\n",
            "[I 2025-06-12 09:39:54,671] Trial 7 finished with value: 481.1 and parameters: {'one_minus_gamma': 0.00010095783296398445, 'max_grad_norm': 0.4786222057654153, 'exponent_n_steps': 7, 'learning_rate': 0.0008996846335853337, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 7 with value: 481.1.\n",
            "[I 2025-06-12 09:40:23,040] Trial 8 finished with value: 463.6 and parameters: {'one_minus_gamma': 0.00035606177672072123, 'max_grad_norm': 0.49196803527143873, 'exponent_n_steps': 8, 'learning_rate': 0.002910350212928796, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 7 with value: 481.1.\n",
            "[I 2025-06-12 09:40:55,476] Trial 9 finished with value: 500.0 and parameters: {'one_minus_gamma': 0.008262752774391171, 'max_grad_norm': 0.4988993250029, 'exponent_n_steps': 5, 'learning_rate': 0.0009036800602866176, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:41:33,076] Trial 10 finished with value: 9.5 and parameters: {'one_minus_gamma': 0.007654797065370172, 'max_grad_norm': 0.4276333924326995, 'exponent_n_steps': 3, 'learning_rate': 0.03300074768845602, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:42:04,835] Trial 11 finished with value: 138.9 and parameters: {'one_minus_gamma': 0.08561534553697434, 'max_grad_norm': 0.49842108234763394, 'exponent_n_steps': 5, 'learning_rate': 0.0009002223266210503, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:42:35,400] Trial 12 finished with value: 392.9 and parameters: {'one_minus_gamma': 0.007621459534012113, 'max_grad_norm': 0.4554872234898885, 'exponent_n_steps': 6, 'learning_rate': 0.00044084605897060813, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:43:05,790] Trial 13 finished with value: 500.0 and parameters: {'one_minus_gamma': 0.0004338676441916004, 'max_grad_norm': 0.45943248291393035, 'exponent_n_steps': 6, 'learning_rate': 0.005175846409724955, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:43:39,324] Trial 14 finished with value: 44.6 and parameters: {'one_minus_gamma': 0.00042913443902935054, 'max_grad_norm': 0.42489126570591434, 'exponent_n_steps': 4, 'learning_rate': 0.008202466146587633, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:44:08,172] Trial 15 finished with value: 9.5 and parameters: {'one_minus_gamma': 0.003222336477326619, 'max_grad_norm': 0.4553327849923281, 'exponent_n_steps': 6, 'learning_rate': 0.1485791717578959, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:44:41,767] Trial 16 finished with value: 149.9 and parameters: {'one_minus_gamma': 0.004097294434259803, 'max_grad_norm': 0.39948286438253583, 'exponent_n_steps': 4, 'learning_rate': 0.004083138511615677, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:45:10,447] Trial 17 finished with value: 118.7 and parameters: {'one_minus_gamma': 0.023388281427777047, 'max_grad_norm': 0.4692958480794096, 'exponent_n_steps': 8, 'learning_rate': 0.00023321280468084326, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:45:42,328] Trial 18 finished with value: 266.5 and parameters: {'one_minus_gamma': 0.00039643173176913117, 'max_grad_norm': 0.43085717444916594, 'exponent_n_steps': 4, 'learning_rate': 0.002085402517430295, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:46:14,635] Trial 19 finished with value: 208.1 and parameters: {'one_minus_gamma': 0.0011274364044843253, 'max_grad_norm': 0.40445173354871017, 'exponent_n_steps': 6, 'learning_rate': 0.010965281905779611, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:46:49,696] Trial 20 finished with value: 110.1 and parameters: {'one_minus_gamma': 0.0002099399167953067, 'max_grad_norm': 0.369048154575029, 'exponent_n_steps': 5, 'learning_rate': 7.013628193178234e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:47:21,125] Trial 21 finished with value: 294.8 and parameters: {'one_minus_gamma': 0.0001840475379181496, 'max_grad_norm': 0.47918426464336783, 'exponent_n_steps': 7, 'learning_rate': 0.0009777512179984806, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:47:55,061] Trial 22 finished with value: 428.9 and parameters: {'one_minus_gamma': 0.0006772044746225003, 'max_grad_norm': 0.49833094389327687, 'exponent_n_steps': 8, 'learning_rate': 0.0008912343822757564, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:48:27,116] Trial 23 finished with value: 172.5 and parameters: {'one_minus_gamma': 0.0002309687834281705, 'max_grad_norm': 0.4740586532039551, 'exponent_n_steps': 6, 'learning_rate': 0.006150621239338369, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:49:01,142] Trial 24 finished with value: 406.1 and parameters: {'one_minus_gamma': 0.005463870698583285, 'max_grad_norm': 0.4455685173246352, 'exponent_n_steps': 7, 'learning_rate': 0.00034897851215578057, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:49:32,196] Trial 25 finished with value: 500.0 and parameters: {'one_minus_gamma': 0.0015837290597985752, 'max_grad_norm': 0.4766437461288706, 'exponent_n_steps': 6, 'learning_rate': 0.001516956038694321, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:50:01,660] Trial 26 finished with value: 9.1 and parameters: {'one_minus_gamma': 0.002124909567287219, 'max_grad_norm': 0.4399594648479258, 'exponent_n_steps': 5, 'learning_rate': 0.14024355986210846, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:50:40,218] Trial 27 finished with value: 65.6 and parameters: {'one_minus_gamma': 0.001853162648692653, 'max_grad_norm': 0.41198769892451237, 'exponent_n_steps': 4, 'learning_rate': 0.002093171928301663, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
            "[I 2025-06-12 09:51:11,973] Trial 28 finished with value: 9.2 and parameters: {'one_minus_gamma': 0.016521266890261135, 'max_grad_norm': 0.4650965203307924, 'exponent_n_steps': 6, 'learning_rate': 0.014314399018629194, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 29\n",
            "Best trial: 500.0\n",
            "Params: \n",
            "  one_minus_gamma: 0.008262752774391171\n",
            "  max_grad_norm: 0.4988993250029\n",
            "  exponent_n_steps: 5\n",
            "  learning_rate: 0.0009036800602866176\n",
            "  net_arch: small\n",
            "  activation_fn: tanh\n",
            "User Attributes: \n",
            "  gamma: 0.9917372472256089\n",
            "  n_steps: 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"58ca60c7-123b-4640-abbf-91423266d753\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"58ca60c7-123b-4640-abbf-91423266d753\")) {                    Plotly.newPlot(                        \"58ca60c7-123b-4640-abbf-91423266d753\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28],\"y\":[9.2,9.2,9.3,91.7,116.7,122.5,84.9,481.1,463.6,500.0,9.5,138.9,392.9,500.0,44.6,9.5,149.9,118.7,266.5,208.1,110.1,294.8,428.9,172.5,406.1,500.0,9.1,65.6,9.2],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28],\"y\":[9.2,9.2,9.3,91.7,116.7,122.5,122.5,481.1,481.1,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('58ca60c7-123b-4640-abbf-91423266d753');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2c52a37f-620f-4dad-8538-8f731bd2c795\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2c52a37f-620f-4dad-8538-8f731bd2c795\")) {                    Plotly.newPlot(                        \"2c52a37f-620f-4dad-8538-8f731bd2c795\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"net_arch (CategoricalDistribution): 0.0022277000092851508\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"activation_fn (CategoricalDistribution): 0.003847729676779038\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"exponent_n_steps (IntDistribution): 0.030083908448970752\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"one_minus_gamma (FloatDistribution): 0.08345023339470921\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.24689730564698437\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"max_grad_norm (FloatDistribution): 0.6334931228232714\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"\\u003c0.01\",\"0.03\",\"0.08\",\"0.25\",\"0.63\"],\"textposition\":\"outside\",\"x\":[0.0022277000092851508,0.003847729676779038,0.030083908448970752,0.08345023339470921,0.24689730564698437,0.6334931228232714],\"y\":[\"net_arch\",\"activation_fn\",\"exponent_n_steps\",\"one_minus_gamma\",\"learning_rate\",\"max_grad_norm\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2c52a37f-620f-4dad-8538-8f731bd2c795');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice: Tune a PPO agent that plays LunarLander-v2"
      ],
      "metadata": {
        "id": "pkPhLjr0kBk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create a config"
      ],
      "metadata": {
        "id": "IDUcW5-REo8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "                                          ###########################\n",
        "                                          # Step 1: Create a config #\n",
        "                                          ###########################\n",
        "\n",
        "# Hyperparameter Optimization Loop\n",
        "N_TRIALS = 100 # Maximum number of trials during Hyperparameter Optimization Loop\n",
        "N_JOBS = 1 # Number of parallel jobs to run during each trials in Hyperparameter Optimization Loop\n",
        "N_STARTUP_TRIALS = 5 # Number of trials to perform random sampling (without relying on sampler) during the Hypeparameter Optimization Loop (To create the initial database)\n",
        "TIMEOUT = int(60*15) # Maximum number of times (in seconds) the entire loop is allowed up to.\n",
        "\n",
        "# Evaluation Parameter for each set of hyperparameter\n",
        "N_TIMESTEPS = int(1e4) # Training budget - Number of time steps in one FULL TRIAL for each set of hyperparameter.\n",
        "N_EVALUATIONS = 2 # Number of intermediate evaluations performed in one FULL TRIAL for each set of hyperparameter.\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS) # Step interval for each intermediate evaluations during one FULL TRIAL.\n",
        "N_EVAL_EPISODES = 10 # Number of episodes to be sampled for each evaluation.\n",
        "\n",
        "\n",
        "# Environment Parameter\n",
        "N_EVAL_ENVS = 16 # Number of environments used in parallel during evaluation.\n",
        "\n",
        "ENV_ID = \"LunarLander-v2\" # ID of the environments, to be initiated with gym.make()\n",
        "\n",
        "# Algorithm Parameter\n",
        "ALGO_NAME = \"PPO\""
      ],
      "metadata": {
        "id": "P6v-ottvE2AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define the search space"
      ],
      "metadata": {
        "id": "AGRWJ6JIE2gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "                            #############################################################\n",
        "                            # Step 2: Define a function that samples the hyperparameter #\n",
        "                            #############################################################\n",
        "\n",
        "def sample_ppo_params(trial):\n",
        "\n",
        "  \"\"\"\n",
        "  Sample a set of hyperparameter to be trial'd.\n",
        "\n",
        "  Args:\n",
        "    trial (optuna.Trial) : An Optuna trial object.\n",
        "\n",
        "  Returns:\n",
        "    params (dict): The hyperparameters to be trial'd. Its key matches the keywords used in defining models.\n",
        "  \"\"\"\n",
        "\n",
        "  # To study the hyperparameter to be updated.\n",
        "\n",
        "  ###################\n",
        "  # Discount factor #\n",
        "  ###################\n",
        "  # suggest.float -> sample from a continuos space (float)\n",
        "  # \"gamma\" - name (to be showcased in the final plot)\n",
        "  # log - means sample from log space\n",
        "  gamma = 1 - trial.suggest_float(\"one_minus_gamma\", 0.0001, 0.1, log = True)\n",
        "\n",
        "  # Create another attribute to store the actual gamma value\n",
        "  trial.set_user_attr(\"gamma\", gamma)\n",
        "\n",
        "  #######################################\n",
        "  # Maximum value for gradient clipping #\n",
        "  #######################################\n",
        "  max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 0.5, log=True)\n",
        "\n",
        "  ##########################################################\n",
        "  # Number of steps to run for each environment per update #\n",
        "  ##########################################################\n",
        "  n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 11)\n",
        "\n",
        "  # Create another attribute to store the actual n_steps\n",
        "  trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "  #################\n",
        "  # Learning_rate #\n",
        "  #################\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n",
        "\n",
        "  ########################\n",
        "  # Network architecture #\n",
        "  ########################\n",
        "  net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
        "\n",
        "  # The net_arch expects a list, that is why it is wrapped in a list\n",
        "  net_arch = [{\"pi\": [64], \"vf\": [64]} if net_arch == 'tiny' \\\n",
        "              else {\"pi\" : [64, 64], \"vf\" : [64, 64]}]\n",
        "\n",
        "  #######################\n",
        "  # Activation Function #\n",
        "  #######################\n",
        "  activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
        "\n",
        "  activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "\n",
        "\n",
        "  # Note: The key used in this dictionary match the key used in defining the models\n",
        "  # Therefore, the naming convention must be followed.\n",
        "  params = {\"n_steps\": n_steps,\n",
        "          \"gamma\": gamma,\n",
        "          \"learning_rate\": learning_rate,\n",
        "          \"max_grad_norm\": max_grad_norm,\n",
        "          \"policy_kwargs\": {\"net_arch\": net_arch,\n",
        "                            \"activation_fn\": activation_fn}}\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "NnMTyzx7E79J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define objective functions"
      ],
      "metadata": {
        "id": "1G7FlGQSE8hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "                                ##############################\n",
        "                                # Step 3: Objective function #\n",
        "                                ##############################\n",
        "                                # 3.1: Callback\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "\n",
        "  \"\"\"\n",
        "  Callback used for evaluating and reporting a trial.\n",
        "\n",
        "  Args:\n",
        "    eval_env (gym.env): An evaluation environment.\n",
        "    trial (Optuna.trial): An Optuna trial object.\n",
        "    n_eval_episodes (int): Number of evaluation episodes for each evaluation.\n",
        "    eval_freq (int): Step interval for an intermediate evaluation in each trial.\n",
        "    deterministic (boolean): Whether the evaluation should use stochastic or deterministic policy.\n",
        "    verbose (int):\n",
        "\n",
        "  Returns:\n",
        "    out (boolean):\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose = 0):\n",
        "\n",
        "    super().__init__(eval_env = eval_env, n_eval_episodes = n_eval_episodes,\n",
        "                    eval_freq = eval_freq, deterministic = deterministic,\n",
        "                    verbose = verbose)\n",
        "    self.trial = trial\n",
        "    self.eval_idx = 0\n",
        "    self.is_pruned = False\n",
        "\n",
        "  def _on_step(self):\n",
        "    if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "      super()._on_step()\n",
        "      self.eval_idx += 1\n",
        "\n",
        "      # Send report to optuna\n",
        "      self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "\n",
        "      # Prune trial if needed\n",
        "      if self.trial.should_prune():\n",
        "        self.is_pruned = True\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "                            # 3.2: The definition of the objective score.\n",
        "def objective(trial):\n",
        "\n",
        "  \"\"\"\n",
        "  A function that returns the objective score that decides the quality of a set of hyperparameter.\n",
        "\n",
        "  Args:\n",
        "    trial (optuna.Trial): An Optuna trial object.\n",
        "\n",
        "  Returns:\n",
        "    objective_score (float): The score that represents the quality of this set of hyperparameter.\n",
        "  \"\"\"\n",
        "\n",
        "  # Creat the default keyword arguments (those that wasnt defined in the hyperparameter sampling function)\n",
        "  kwargs = {\"policy\": \"MlpPolicy\",\n",
        "            \"env\": ENV_ID}\n",
        "\n",
        "  # Update with the inclusion of the sampled hyperparameter\n",
        "  kwargs.update(sample_ppo_params(trial))\n",
        "\n",
        "  # Create a model using the sampled hyperparameter\n",
        "  model = PPO(**kwargs)\n",
        "\n",
        "  # Create the environments\n",
        "  eval_envs = make_vec_env(env_id = ENV_ID,\n",
        "                           n_envs = N_EVAL_ENVS)\n",
        "\n",
        "  # Create the call back for reporting evaluation results\n",
        "  eval_callback = TrialEvalCallback(eval_env = eval_envs,\n",
        "                                    trial = trial,\n",
        "                                    n_eval_episodes = N_EVAL_EPISODES,\n",
        "                                    eval_freq = EVAL_FREQ,\n",
        "                                    deterministic = True)\n",
        "\n",
        "  nan_encountered = False\n",
        "  try:\n",
        "    model.learn(N_TIMESTEPS, callback = eval_callback)\n",
        "  except AssertionError as e:\n",
        "    # Sometimes, randomly sampled error can lead to NaN\n",
        "    print(e)\n",
        "    nan_encountered = True\n",
        "  finally:\n",
        "    # At the end of training or if error is encountered\n",
        "    # Free Memory\n",
        "    model.env.close()\n",
        "    eval_envs.close()\n",
        "\n",
        "  # Inform the optimizer that a non-valid hyperparameter is sampled\n",
        "  if nan_encountered:\n",
        "    return float('nan')\n",
        "\n",
        "  if eval_callback.is_pruned:\n",
        "    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return eval_callback.last_mean_reward"
      ],
      "metadata": {
        "id": "ZETCoku6FBvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Hyperparameter Optimization Loop"
      ],
      "metadata": {
        "id": "M9lfv9NUFCV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "                            #############################\n",
        "                            # Step 4: Optimization Loop #\n",
        "                            #############################\n",
        "\n",
        "# Set PyTorch num threads to 1 for faster training\n",
        "# Parallel environement will demand heavy use of CPU.\n",
        "# Therefore, this line limits to the usage of cpu for PyTorch to be only 1 line.\n",
        "th.set_num_threads(1)\n",
        "\n",
        "# Select a sampler\n",
        "# https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html\n",
        "# n_startup_trials -> Number of trials at the beginning that sample a set of hyperparameter randomly instead of using the algorithm\n",
        "# This allows the creation of initial database.\n",
        "sampler = TPESampler(n_startup_trials = N_STARTUP_TRIALS)\n",
        "\n",
        "# Select a scheduler / pruner\n",
        "# https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html\n",
        "# n_startup_trials -> Pruning is disabaled at the beginning for this many trials for initial database creation.\n",
        "# n_warmup_steps -> Number of steps in each trial that disable the pruning.\n",
        "pruner = MedianPruner(n_startup_trials = N_STARTUP_TRIALS,\n",
        "                      n_warmup_steps = N_TIMESTEPS // 3)\n",
        "\n",
        "# Create a study for Hyperparameter Optimization\n",
        "# https://optuna.readthedocs.io/en/stable/reference/generated/optuna.create_study.html\n",
        "study = optuna.create_study(sampler = sampler,\n",
        "                            pruner = pruner,\n",
        "                            direction = \"maximize\")\n",
        "\n",
        "try:\n",
        "  # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize\n",
        "  study.optimize(objective,\n",
        "                 n_trials = N_TRIALS,\n",
        "                 timeout = TIMEOUT,\n",
        "                 n_jobs = N_JOBS)\n",
        "except KeyboardInterrupt:\n",
        "  pass\n",
        "\n",
        "# Print the meta info for the hyperparameter optimization process\n",
        "print(f\"Number of finished trials: {len(study.trials)}\")\n",
        "trial = study.best_trial\n",
        "print(f\"Best trial: {trial.value}\")\n",
        "\n",
        "print(\"Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"User Attributes: \")\n",
        "for key, value in trial.user_attrs.items():\n",
        "  print(f\"  {key}: {value}\")\n",
        "\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(f\"study_result_{ALGO_NAME}_{ENV_ID}.csv\")\n",
        "\n",
        "# Show plot\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O2I2LM1ikB2D",
        "outputId": "f6a902fd-9412-42b6-ad17-b7891bb61adc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-12 10:33:00,511] A new study created in memory with name: no-name-fd0bfab8-64ec-40c1-9241-687385342959\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:460: UserWarning:\n",
            "\n",
            "As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "\n",
            "[I 2025-06-12 10:33:32,344] Trial 0 finished with value: -161.2994264 and parameters: {'one_minus_gamma': 0.0013394327939557347, 'max_grad_norm': 0.37610299115911333, 'exponent_n_steps': 7, 'learning_rate': 0.0015267266493195163, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -161.2994264.\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning:\n",
            "\n",
            "You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 32`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=32 and n_envs=1)\n",
            "\n",
            "[I 2025-06-12 10:34:04,336] Trial 1 finished with value: -557.0485559 and parameters: {'one_minus_gamma': 0.018047944586814742, 'max_grad_norm': 0.4083973012638097, 'exponent_n_steps': 5, 'learning_rate': 0.011654964843614892, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -161.2994264.\n",
            "[I 2025-06-12 10:34:29,463] Trial 2 finished with value: -896.559915 and parameters: {'one_minus_gamma': 0.011128973123313377, 'max_grad_norm': 0.31249511359003623, 'exponent_n_steps': 8, 'learning_rate': 3.056904899209025e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -161.2994264.\n",
            "[I 2025-06-12 10:35:06,816] Trial 3 finished with value: -398.8754024 and parameters: {'one_minus_gamma': 0.00016957221011093326, 'max_grad_norm': 0.446493595885835, 'exponent_n_steps': 5, 'learning_rate': 0.0012527595196519079, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -161.2994264.\n",
            "[I 2025-06-12 10:35:42,478] Trial 4 finished with value: -1054.8060380000002 and parameters: {'one_minus_gamma': 0.04818296661605675, 'max_grad_norm': 0.407393405200591, 'exponent_n_steps': 5, 'learning_rate': 0.00015032794826471812, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: -161.2994264.\n",
            "[I 2025-06-12 10:36:04,132] Trial 5 finished with value: -144.7467941 and parameters: {'one_minus_gamma': 0.0010493525406162696, 'max_grad_norm': 0.32689356865156666, 'exponent_n_steps': 10, 'learning_rate': 0.7352439564709278, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 5 with value: -144.7467941.\n",
            "[I 2025-06-12 10:36:26,334] Trial 6 finished with value: -136.3407456 and parameters: {'one_minus_gamma': 0.0008344402976995819, 'max_grad_norm': 0.30251073421860347, 'exponent_n_steps': 11, 'learning_rate': 0.9722328931990518, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 6 with value: -136.3407456.\n",
            "[I 2025-06-12 10:36:49,618] Trial 7 finished with value: -456.31194050000005 and parameters: {'one_minus_gamma': 0.0001202003304370596, 'max_grad_norm': 0.34818209251534243, 'exponent_n_steps': 11, 'learning_rate': 0.9849334691560303, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 6 with value: -136.3407456.\n",
            "[I 2025-06-12 10:37:15,754] Trial 8 finished with value: -248.3536174 and parameters: {'one_minus_gamma': 0.0005448934967618907, 'max_grad_norm': 0.4924597946480634, 'exponent_n_steps': 9, 'learning_rate': 0.048290913237397703, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 6 with value: -136.3407456.\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning:\n",
            "\n",
            "You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 8`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 8\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=8 and n_envs=1)\n",
            "\n",
            "[I 2025-06-12 10:38:27,704] Trial 9 finished with value: -546.4253692 and parameters: {'one_minus_gamma': 0.0042327807137144775, 'max_grad_norm': 0.30268539327789484, 'exponent_n_steps': 3, 'learning_rate': 0.07593518338596765, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 6 with value: -136.3407456.\n",
            "[I 2025-06-12 10:38:51,401] Trial 10 finished with value: -556.610721 and parameters: {'one_minus_gamma': 0.003500839678527354, 'max_grad_norm': 0.3589123476395259, 'exponent_n_steps': 11, 'learning_rate': 0.11682116823713315, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 6 with value: -136.3407456.\n",
            "[I 2025-06-12 10:39:13,302] Trial 11 finished with value: -128.4883158 and parameters: {'one_minus_gamma': 0.000955171523954141, 'max_grad_norm': 0.3275641686920449, 'exponent_n_steps': 10, 'learning_rate': 0.8923983660198801, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 11 with value: -128.4883158.\n",
            "[I 2025-06-12 10:39:35,808] Trial 12 finished with value: -125.08086270000001 and parameters: {'one_minus_gamma': 0.00044601985313627134, 'max_grad_norm': 0.3335884800377129, 'exponent_n_steps': 9, 'learning_rate': 0.2793849475657967, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 12 with value: -125.08086270000001.\n",
            "[I 2025-06-12 10:40:00,235] Trial 13 finished with value: -95.36918649999998 and parameters: {'one_minus_gamma': 0.00024017825495791827, 'max_grad_norm': 0.3369241058926242, 'exponent_n_steps': 9, 'learning_rate': 0.012240249297239322, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 13 with value: -95.36918649999998.\n",
            "[I 2025-06-12 10:40:25,584] Trial 14 finished with value: -165.33153520000002 and parameters: {'one_minus_gamma': 0.00035094263604197183, 'max_grad_norm': 0.3463523372603283, 'exponent_n_steps': 8, 'learning_rate': 0.009246874747254313, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 13 with value: -95.36918649999998.\n",
            "[I 2025-06-12 10:40:50,231] Trial 15 finished with value: -88.5928761 and parameters: {'one_minus_gamma': 0.0003189053701602661, 'max_grad_norm': 0.3794603696820127, 'exponent_n_steps': 9, 'learning_rate': 0.013170246935540999, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:41:14,070] Trial 16 finished with value: -207.7539197 and parameters: {'one_minus_gamma': 0.00023003676626427583, 'max_grad_norm': 0.3793031026328811, 'exponent_n_steps': 7, 'learning_rate': 0.008321443918674171, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:41:38,856] Trial 17 finished with value: -539.3416276999999 and parameters: {'one_minus_gamma': 0.00010943714159848724, 'max_grad_norm': 0.4120872773461197, 'exponent_n_steps': 9, 'learning_rate': 0.00034356311595884644, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:42:03,151] Trial 18 finished with value: -135.08106410000002 and parameters: {'one_minus_gamma': 0.0026686466068853664, 'max_grad_norm': 0.36842310593107674, 'exponent_n_steps': 6, 'learning_rate': 0.0223695796749937, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:42:44,921] Trial 19 finished with value: -248.58793529999997 and parameters: {'one_minus_gamma': 0.00023258136426446895, 'max_grad_norm': 0.4390121664946945, 'exponent_n_steps': 8, 'learning_rate': 0.0037519259703560535, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:43:09,425] Trial 20 finished with value: -784.3009198 and parameters: {'one_minus_gamma': 0.0020446835781897797, 'max_grad_norm': 0.3540290774001589, 'exponent_n_steps': 10, 'learning_rate': 0.00046620778430158104, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:43:33,158] Trial 21 finished with value: -103.82632729999997 and parameters: {'one_minus_gamma': 0.0004212581895487386, 'max_grad_norm': 0.32987506071540024, 'exponent_n_steps': 9, 'learning_rate': 0.10403295166335817, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:44:02,518] Trial 22 finished with value: -177.97358309999998 and parameters: {'one_minus_gamma': 0.00034335945819895534, 'max_grad_norm': 0.31898338064874115, 'exponent_n_steps': 9, 'learning_rate': 0.027270251738113725, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:44:24,417] Trial 23 finished with value: -124.23811870000002 and parameters: {'one_minus_gamma': 0.0005830199280769311, 'max_grad_norm': 0.33757194689711917, 'exponent_n_steps': 7, 'learning_rate': 0.15524313698583353, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:44:55,728] Trial 24 finished with value: -181.3953086 and parameters: {'one_minus_gamma': 0.0002202354989889644, 'max_grad_norm': 0.39310597522750507, 'exponent_n_steps': 8, 'learning_rate': 0.0040106298948556236, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:45:28,295] Trial 25 finished with value: -401.83314170000006 and parameters: {'one_minus_gamma': 0.008123199428851894, 'max_grad_norm': 0.36772967620850483, 'exponent_n_steps': 10, 'learning_rate': 0.032232858501161275, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:45:53,524] Trial 26 finished with value: -599.0589193 and parameters: {'one_minus_gamma': 0.09264911026713278, 'max_grad_norm': 0.3892830120404527, 'exponent_n_steps': 9, 'learning_rate': 0.3018682414376205, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:46:17,659] Trial 27 finished with value: -684.2835556000001 and parameters: {'one_minus_gamma': 0.0015376410741235718, 'max_grad_norm': 0.3155117708146964, 'exponent_n_steps': 6, 'learning_rate': 0.015294514353099304, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:46:40,919] Trial 28 finished with value: -151.72921430000002 and parameters: {'one_minus_gamma': 0.00015430068425744545, 'max_grad_norm': 0.3408522439500022, 'exponent_n_steps': 10, 'learning_rate': 0.06340505929830537, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:47:12,048] Trial 29 finished with value: -163.62037809999998 and parameters: {'one_minus_gamma': 0.0006589550321398196, 'max_grad_norm': 0.36281408091099193, 'exponent_n_steps': 8, 'learning_rate': 0.0014009053928601496, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:47:36,167] Trial 30 finished with value: -153.85446280000002 and parameters: {'one_minus_gamma': 0.00029016876648193455, 'max_grad_norm': 0.4345154151938904, 'exponent_n_steps': 7, 'learning_rate': 0.005307583744177714, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:47:57,522] Trial 31 finished with value: -143.46345209999998 and parameters: {'one_minus_gamma': 0.0005628484883917151, 'max_grad_norm': 0.3373714323186136, 'exponent_n_steps': 7, 'learning_rate': 0.1436292233140212, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n",
            "[I 2025-06-12 10:48:20,066] Trial 32 finished with value: -237.58871460000006 and parameters: {'one_minus_gamma': 0.0014223415414867586, 'max_grad_norm': 0.32206080869965326, 'exponent_n_steps': 6, 'learning_rate': 0.12665821131762017, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -88.5928761.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 33\n",
            "Best trial: -88.5928761\n",
            "Params: \n",
            "  one_minus_gamma: 0.0003189053701602661\n",
            "  max_grad_norm: 0.3794603696820127\n",
            "  exponent_n_steps: 9\n",
            "  learning_rate: 0.013170246935540999\n",
            "  net_arch: tiny\n",
            "  activation_fn: tanh\n",
            "User Attributes: \n",
            "  gamma: 0.9996810946298398\n",
            "  n_steps: 512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"afa4d5b0-1d39-478c-bdb2-95ebc23e65b4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"afa4d5b0-1d39-478c-bdb2-95ebc23e65b4\")) {                    Plotly.newPlot(                        \"afa4d5b0-1d39-478c-bdb2-95ebc23e65b4\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32],\"y\":[-161.2994264,-557.0485559,-896.559915,-398.8754024,-1054.8060380000002,-144.7467941,-136.3407456,-456.31194050000005,-248.3536174,-546.4253692,-556.610721,-128.4883158,-125.08086270000001,-95.36918649999998,-165.33153520000002,-88.5928761,-207.7539197,-539.3416276999999,-135.08106410000002,-248.58793529999997,-784.3009198,-103.82632729999997,-177.97358309999998,-124.23811870000002,-181.3953086,-401.83314170000006,-599.0589193,-684.2835556000001,-151.72921430000002,-163.62037809999998,-153.85446280000002,-143.46345209999998,-237.58871460000006],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32],\"y\":[-161.2994264,-161.2994264,-161.2994264,-161.2994264,-161.2994264,-144.7467941,-136.3407456,-136.3407456,-136.3407456,-136.3407456,-136.3407456,-128.4883158,-125.08086270000001,-95.36918649999998,-95.36918649999998,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761,-88.5928761],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('afa4d5b0-1d39-478c-bdb2-95ebc23e65b4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"35f56123-461a-46c8-9723-10e5d1b57262\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"35f56123-461a-46c8-9723-10e5d1b57262\")) {                    Plotly.newPlot(                        \"35f56123-461a-46c8-9723-10e5d1b57262\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"activation_fn (CategoricalDistribution): 0.040767370885942615\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"net_arch (CategoricalDistribution): 0.06637126432290605\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"max_grad_norm (FloatDistribution): 0.11118459204938916\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"exponent_n_steps (IntDistribution): 0.11928492518406236\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.1334745572245883\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"one_minus_gamma (FloatDistribution): 0.5289172903331115\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.04\",\"0.07\",\"0.11\",\"0.12\",\"0.13\",\"0.53\"],\"textposition\":\"outside\",\"x\":[0.040767370885942615,0.06637126432290605,0.11118459204938916,0.11928492518406236,0.1334745572245883,0.5289172903331115],\"y\":[\"activation_fn\",\"net_arch\",\"max_grad_norm\",\"exponent_n_steps\",\"learning_rate\",\"one_minus_gamma\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('35f56123-461a-46c8-9723-10e5d1b57262');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice: Tune a DQN agent that plays Atari Games - Space Invader"
      ],
      "metadata": {
        "id": "jybSKHrm6zRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "YFJVoU6s8npc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "976hxtju6y7b",
        "outputId": "6e53849c-8067-479a-8013-23f5698d456c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo\n",
            "  Cloning https://github.com/DLR-RM/rl-baselines3-zoo to /tmp/pip-req-build-cf5dfh_t\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-cf5dfh_t\n",
            "  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit 577616cb9f13341579953cb0f6111e007acc0a1d\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sb3_contrib<3.0,>=2.6.1a1 (from rl_zoo3==2.6.1a1)\n",
            "  Downloading sb3_contrib-2.6.1a1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting gymnasium<1.2.0,>=0.29.1 (from rl_zoo3==2.6.1a1)\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting huggingface_sb3<4.0,>=3.0 (from rl_zoo3==2.6.1a1)\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rl_zoo3==2.6.1a1) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from rl_zoo3==2.6.1a1) (13.9.4)\n",
            "Requirement already satisfied: optuna>=3.0 in /usr/local/lib/python3.11/dist-packages (from rl_zoo3==2.6.1a1) (4.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from rl_zoo3==2.6.1a1) (6.0.2)\n",
            "Collecting pytablewriter~=1.2 (from rl_zoo3==2.6.1a1)\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting shimmy~=2.0 (from rl_zoo3==2.6.1a1)\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.1a1) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.1a1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.1a1) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.1a1) (0.0.4)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (0.32.4)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (1.1.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0->rl_zoo3==2.6.1a1) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0->rl_zoo3==2.6.1a1) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0->rl_zoo3==2.6.1a1) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0->rl_zoo3==2.6.1a1) (2.0.41)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter~=1.2->rl_zoo3==2.6.1a1) (75.2.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter~=1.2->rl_zoo3==2.6.1a1)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=1.2->rl_zoo3==2.6.1a1)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter~=1.2->rl_zoo3==2.6.1a1)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter~=1.2->rl_zoo3==2.6.1a1)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=1.2->rl_zoo3==2.6.1a1)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.1a1)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting stable_baselines3<3.0,>=2.6.1a1 (from sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1)\n",
            "  Downloading stable_baselines3-2.6.1a1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->rl_zoo3==2.6.1a1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->rl_zoo3==2.6.1a1) (2.19.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.6.1a1) (1.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (1.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3==2.6.1a1) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=1.2->rl_zoo3==2.6.1a1) (5.2.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.0->rl_zoo3==2.6.1a1) (3.2.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.1a1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.1a1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.1a1) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (3.2.3)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.1a1) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.1a1->sb3_contrib<3.0,>=2.6.1a1->rl_zoo3==2.6.1a1) (3.0.2)\n",
            "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sb3_contrib-2.6.1a1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading stable_baselines3-2.6.1a1-py3-none-any.whl (185 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.3/185.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Building wheels for collected packages: rl_zoo3\n",
            "  Building wheel for rl_zoo3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl_zoo3: filename=rl_zoo3-2.6.1a1-py3-none-any.whl size=77889 sha256=17e96a0a924a54331fb8c944a0b65d3e1e5705801347f2e97bd28b9860d66d89\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-11bk_idc/wheels/79/a7/a1/afc7c6c739a99c02b2cba585d219d453a80ab2bff20fb6526f\n",
            "Successfully built rl_zoo3\n",
            "Installing collected packages: tcolorpy, pathvalidate, mbstrdecoder, gymnasium, typepy, shimmy, huggingface_sb3, stable_baselines3, DataProperty, tabledata, sb3_contrib, pytablewriter, rl_zoo3\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.28.1\n",
            "    Uninstalling gymnasium-0.28.1:\n",
            "      Successfully uninstalled gymnasium-0.28.1\n",
            "  Attempting uninstall: stable_baselines3\n",
            "    Found existing installation: stable-baselines3 2.0.0a5\n",
            "    Uninstalling stable-baselines3-2.0.0a5:\n",
            "      Successfully uninstalled stable-baselines3-2.0.0a5\n",
            "Successfully installed DataProperty-1.1.0 gymnasium-1.1.1 huggingface_sb3-3.0 mbstrdecoder-1.1.4 pathvalidate-3.2.3 pytablewriter-1.2.1 rl_zoo3-2.6.1a1 sb3_contrib-2.6.1a1 shimmy-2.0.0 stable_baselines3-2.6.1a1 tabledata-1.3.4 tcolorpy-0.1.7 typepy-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom_license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rZXv6dyq8wXv",
        "outputId": "1792dd03-32fa-4a3d-84d0-ce1a666dc6b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.11.1)\n",
            "Requirement already satisfied: gymnasium[accept-rom_license] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "\u001b[33mWARNING: gymnasium 1.1.1 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom_license]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom_license]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom_license]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom_license]) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a config file\n",
        "\n",
        "* Save the config file as `dqn.yml`\n",
        "\n",
        "* Note: The config file is only moslty used as a placeholder. During Hyperparameter optimization, a set of hyperparameter will be randomly sampled, thus replacing these values.\n",
        "\n",
        "* The type and range of hyperparameter values to be sampled may be referred to: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/rl_zoo3/hyperparams_opt.py#L222"
      ],
      "metadata": {
        "id": "N_KB1ZuaAqQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The default config file\n",
        "SpaceInvadersNoFrameskip-v4:\n",
        "  env_wrapper:\n",
        "    - stable_baselines3.common.atari_wrappers.AtariWrapper\n",
        "  frame_stack: 4 #Every 4 frame as 1 input to allow the model to learn the trajectories of the object.\n",
        "  policy: 'CnnPolicy'\n",
        "  n_timesteps: !!float 1e2 # 1e6 (Recommended, but shortened in this notebook as its only for demo)\n",
        "  buffer_size: 100000\n",
        "  learning_rate: !!float 1e-4\n",
        "  batch_size: 32\n",
        "  learning_starts: 100000\n",
        "  target_update_interval: 1000\n",
        "  train_freq: 4\n",
        "  gradient_steps: 1\n",
        "  exploration_fraction: 0.1\n",
        "  exploration_final_eps: 0.01\n",
        "  # If True, you need to deactivate handle_timeout_termination\n",
        "  # in the replay_buffer_kwargs\n",
        "  optimize_memory_usage: False"
      ],
      "metadata": {
        "id": "AcOJuhiOAqi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access the API for hyperparameter optimization (Built-in)\n",
        "\n",
        "* Refer to the raw code to find out the usage: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/rl_zoo3/train.py\n",
        "\n",
        "* The full command is as following:\n",
        "`!python -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml -optimize --optimization-log-path logs/optimization --eval-episodes 10 --n-eval-envs 1 --max-total-trials 100  --n-jobs 1 --sampler \"tpe\" --pruner \"median\" --n-startup-trials 10 --n-evaluations 2`"
      ],
      "metadata": {
        "id": "GO20DLyB81FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml -optimize --optimization-log-path logs/optimization --eval-episodes 10 --n-eval-envs 1 --max-total-trials 100  --n-jobs 1 --sampler \"tpe\" --pruner \"median\" --n-startup-trials 10 --n-evaluations 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b2Wyenfv81YB",
        "outputId": "db025341-565f-4903-a25a-d747618810ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-13 02:13:47.398080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749780827.659864    2022 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749780827.730596    2022 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-13 02:13:48.294532: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "========== SpaceInvadersNoFrameskip-v4 ==========\n",
            "Seed: 3490938613\n",
            "Loading hyperparameters from: dqn.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('batch_size', 32),\n",
            "             ('buffer_size', 100000),\n",
            "             ('env_wrapper',\n",
            "              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n",
            "             ('exploration_final_eps', 0.01),\n",
            "             ('exploration_fraction', 0.1),\n",
            "             ('frame_stack', 4),\n",
            "             ('gradient_steps', 1),\n",
            "             ('learning_rate', 0.0001),\n",
            "             ('learning_starts', 100000),\n",
            "             ('n_timesteps', 100.0),\n",
            "             ('optimize_memory_usage', False),\n",
            "             ('policy', 'CnnPolicy'),\n",
            "             ('target_update_interval', 1000),\n",
            "             ('train_freq', 4)])\n",
            "Using 1 environments\n",
            "A.L.E: Arcade Learning Environment (version 0.11.1+2750686)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Optimizing hyperparameters\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "Sampler: tpe - Pruner: median\n",
            "\u001b[32m[I 2025-06-13 02:13:57,395]\u001b[0m A new study created in memory with name: no-name-2f16408c-98a5-4833-b871-b0e4ce111614\u001b[0m\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "\u001b[32m[I 2025-06-13 02:14:36,191]\u001b[0m Trial 0 finished with value: 253.5 and parameters: {'one_minus_gamma': 0.0002925720048943398, 'batch_size_pow': 7, 'learning_rate': 6.306985547639384e-05, 'train_freq': 9, 'subsample_steps': 4, 'exploration_final_eps': 0.012355737975305092, 'exploration_fraction': 0.4104417373242304, 'target_update_interval': 25, 'net_arch': 'medium'}. Best is trial 0 with value: 253.5.\u001b[0m\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "\u001b[32m[I 2025-06-13 02:15:09,060]\u001b[0m Trial 1 finished with value: 246.0 and parameters: {'one_minus_gamma': 0.0006933497497906717, 'batch_size_pow': 8, 'learning_rate': 0.0008033612943701972, 'train_freq': 9, 'subsample_steps': 3, 'exploration_final_eps': 0.03782588635623921, 'exploration_fraction': 0.1946062176910806, 'target_update_interval': 412, 'net_arch': 'small'}. Best is trial 0 with value: 253.5.\u001b[0m\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Number of finished trials:  3\n",
            "Best trial:\n",
            "Value:  253.5\n",
            "Params: \n",
            "    one_minus_gamma: 0.0002925720048943398\n",
            "    batch_size_pow: 7\n",
            "    learning_rate: 6.306985547639384e-05\n",
            "    train_freq: 9\n",
            "    subsample_steps: 4\n",
            "    exploration_final_eps: 0.012355737975305092\n",
            "    exploration_fraction: 0.4104417373242304\n",
            "    target_update_interval: 25\n",
            "    net_arch: medium\n",
            "User Attributes: \n",
            "    gamma: 0.9997074279951057\n",
            "    batch_size: 128\n",
            "Writing report to logs/dqn/report_SpaceInvadersNoFrameskip-v4_500-trials-100-tpe-median_1749780916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post Notes: How to apply it onto a PyTorch Model?\n",
        "\n",
        "* A good reference link: https://www.geeksforgeeks.org/hyperparameter-tuning-with-optuna-in-pytorch/\n",
        "\n",
        "* The main difference will be on the definition of the objective function and how to manually report back the intermediate and/or final evaluation to optune.\n",
        "\n",
        "* The following codes are generated by chatGPT on how to accomplish both. (Note: It has not yet to be tested)"
      ],
      "metadata": {
        "id": "z7Ouy52Ii5tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    n_units = trial.suggest_int(\"n_units\", 16, 128)\n",
        "\n",
        "    # Model\n",
        "    model = MyModel(n_units)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in val_loader:\n",
        "                output = model(x_val)\n",
        "                val_loss += criterion(output, y_val).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # Report intermediate result to Optuna\n",
        "        trial.report(val_loss, epoch)\n",
        "\n",
        "        # Check whether to prune\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return val_loss  # Final score\n"
      ],
      "metadata": {
        "id": "Og20YMHpjBXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}