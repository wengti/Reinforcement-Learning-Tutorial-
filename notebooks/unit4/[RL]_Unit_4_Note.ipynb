{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wengti/Reinforcement-Learning-Tutorial-/blob/main/notebooks/unit4/%5BRL%5D_Unit_4_Note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0tPv5SSv5k7"
      },
      "source": [
        "# Implementation of Reinforce from scratch to play Cartpole-v1\n",
        "\n",
        "* Environment documentations: https://gymnasium.farama.org/environments/classic_control/cart_pole/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVorOoKkwTwu"
      },
      "source": [
        "## Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v30l_UTFwScI"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.distributions.normal import Normal\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "\n",
        "# For pushing to hub\n",
        "from huggingface_hub import HfApi, snapshot_download\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import json\n",
        "import imageio\n",
        "\n",
        "import tempfile\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MPm_LlBj52lq"
      },
      "outputs": [],
      "source": [
        "# Device\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UuvugXYwLr7"
      },
      "source": [
        "## 0. Visualise the observation space and action space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgv-UBZ4vbF2",
        "outputId": "feed766f-3dfb-4860-f78d-7407bdb174c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of available actions: 2\n",
            "Sample a random action: 0\n",
            "Sample a random observation: [4.745393   2.4669313  0.4147641  0.27528846]\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "print(f\"Number of available actions: {env.action_space.n}\")\n",
        "print(f\"Sample a random action: {env.action_space.sample()}\")\n",
        "\n",
        "print(f\"Sample a random observation: {env.observation_space.sample()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTkTdNuMxJGq"
      },
      "source": [
        "## 1. Build a policy network using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-5z1NmxxITH"
      },
      "outputs": [],
      "source": [
        "class Policy(nn.Module):\n",
        "  \"\"\"\n",
        "  A policy network.\n",
        "\n",
        "  Args:\n",
        "    s_size (int): The size of 1 state space. \\n\n",
        "    h_size (int): The number of hidden nodes in the network. \\n\n",
        "    a_size (int): The number of distinct discrete actions, representing the number of output nodes. \\n\n",
        "  \"\"\"\n",
        "  def __init__(self, s_size, h_size, a_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Sequential(nn.Linear(in_features = s_size,\n",
        "                                       out_features = h_size),\n",
        "                             nn.ReLU())\n",
        "\n",
        "    self.fc2 = nn.Sequential(nn.Linear(in_features = h_size,\n",
        "                                       out_features = a_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    The forward propagation of the policy network.\n",
        "\n",
        "    Args:\n",
        "      x (float tensor): Input to the network representing the observation / state, expected shape: (B, s_size). \\n\n",
        "\n",
        "    Returns:\n",
        "      out(float tensor): Output of the network, representing the probability of taking each distinct discrete action, expecte shape: (B, a_size). \\n\n",
        "    \"\"\"\n",
        "    out = self.fc1(x)\n",
        "    out = self.fc2(out)\n",
        "    out = torch.nn.functional.softmax(out, dim=-1)\n",
        "    return out\n",
        "\n",
        "  def act(self, state):\n",
        "    \"\"\"\n",
        "    Sampling of an action.\n",
        "\n",
        "    Args:\n",
        "      state (float tensor): Input to the network representing the observation / state, expected shape: (B, s_size). \\n\n",
        "\n",
        "    Returns:\n",
        "      action (int / int tensor): The index of the output nodes of the network, sampled based on the output probability of the network. If input (B, s_size) where B > 1, output is in tensor. Else, integer. \\n\n",
        "      log_prob (float tensor): The ln of the probability of the action that was sampled based on the output probability of the newtork.\n",
        "\n",
        "    \"\"\"\n",
        "    probs = self.forward(state).cpu()\n",
        "    m = Categorical(probs)\n",
        "    action = m.sample()\n",
        "    if action.shape[0] == 1:\n",
        "      return action.item(), m.log_prob(action)\n",
        "    else:\n",
        "      return action, m.log_prob(action)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVodeKBD4VGH"
      },
      "source": [
        "## 2. Implementation of Reinforce algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkVg6pu33-sJ"
      },
      "outputs": [],
      "source": [
        " def reinforce(policy, optimizer, env, n_episodes, n_steps, device, gamma, print_every):\n",
        "\n",
        "  \"\"\"\n",
        "  Train a policy network using the reinforce algorithm.\n",
        "\n",
        "  Args:\n",
        "    policy (nn.Module): A policy network. \\n\n",
        "    optimizer (torch.optim): An optimizer. \\n\n",
        "    env (gymnasium.env): An environment. \\n\n",
        "    n_episodes (int): Number of training episodes. \\n\n",
        "    n_steps (int): Maximum number of steps allowed in an episode. \\n\n",
        "    device (str): 'cuda' or 'cpu'\n",
        "    gamma (float): A discount factor, range from 0 to 1.\n",
        "    print_every (int): Number of episode intervals to print the performance of the network. \\n\n",
        "\n",
        "  Returns:\n",
        "    scores (list): A list of integer, each element representing the rewards scored in an episode. \\n\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Create variables to store the rewards scored for every episode\n",
        "  scores = []\n",
        "\n",
        "  # This variable store up to rewards scored for every episode up to \"print_every\" episodes\n",
        "  scores_deque = deque(maxlen = print_every)\n",
        "\n",
        "\n",
        "  ####################\n",
        "  # For each episode #\n",
        "  ####################\n",
        "  for episode in range(1, n_episodes+1):\n",
        "\n",
        "    # Variable to store values for every step within an episode\n",
        "    reward_eps = [] # Reward scored by each step\n",
        "    log_prob_eps = [] # ln (prob of the action taken) for each step\n",
        "    returns_eps = deque(maxlen = n_steps) # discounted returns scored in each step\n",
        "    policy_loss_eps = [] # loss for each step -> ln (prob of the action taken) * discounted return\n",
        "\n",
        "    # Reset the environment for the beginning of each episode\n",
        "    state, info = env.reset()\n",
        "\n",
        "    #################\n",
        "    # For each step #\n",
        "    #################\n",
        "    for _ in range(n_steps):\n",
        "\n",
        "      # Sample an action using the policy network\n",
        "      action, log_prob = policy.act(torch.tensor(state).unsqueeze(0).to(device))\n",
        "\n",
        "      # Step the environment using the sampled action\n",
        "      state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "      # Store the rewards for this step and the ln (prob of this action)\n",
        "      reward_eps.append(reward)\n",
        "      log_prob_eps.append(log_prob)\n",
        "\n",
        "      # Check if this leads to termination or truncation\n",
        "      if terminated or truncated:\n",
        "        break\n",
        "\n",
        "    # Sum the rewards scored for the entire episode and store them\n",
        "    scores.append(sum(reward_eps))\n",
        "    scores_deque.append(sum(reward_eps))\n",
        "\n",
        "    # Calculate the discounted returns\n",
        "    for t in range(len(reward_eps))[::-1]:\n",
        "      returns = reward_eps[t] + gamma * returns_eps[0] if len(returns_eps) > 0 else reward_eps[t]\n",
        "      returns_eps.appendleft(returns)\n",
        "\n",
        "    # Normalize the discounted returns\n",
        "    eps = np.finfo(np.float32).eps.item() # eps is smallest reprsentatable float\n",
        "    returns_eps = torch.tensor(returns_eps) # Convert into torch tensor for later calculation\n",
        "    returns_eps = (returns_eps - returns_eps.mean()) / (returns_eps.std() + eps)\n",
        "\n",
        "    # Calculate the loss\n",
        "    for log_prob, returns in zip(log_prob_eps, returns_eps):\n",
        "      policy_loss_eps.append(-log_prob * returns) # torch tensor * torch tensor\n",
        "    loss = torch.cat(policy_loss_eps).sum() # cat -> makes into one torch tensor, sum() -> summation\n",
        "\n",
        "    # Backward propagation and gradient descent\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print information\n",
        "    if episode % print_every == 0:\n",
        "      print(f\"Current Episode: {episode} | Average reward: {np.mean(scores_deque)}\")\n",
        "\n",
        "  return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9xYJRoiIz2N"
      },
      "source": [
        "## 3. Train the policy network using reinforce algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGuE62iDBetT",
        "outputId": "acd4ffc9-98bd-42b1-864d-9d73621eeb8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Episode: 100 | Average reward: 44.33\n",
            "Current Episode: 200 | Average reward: 308.61\n",
            "Current Episode: 300 | Average reward: 322.93\n",
            "Current Episode: 400 | Average reward: 388.92\n",
            "Current Episode: 500 | Average reward: 352.5\n",
            "Current Episode: 600 | Average reward: 459.3\n",
            "Current Episode: 700 | Average reward: 476.28\n",
            "Current Episode: 800 | Average reward: 500.0\n",
            "Current Episode: 900 | Average reward: 461.11\n",
            "Current Episode: 1000 | Average reward: 379.94\n"
          ]
        }
      ],
      "source": [
        "#0. Create device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 1. Create hyperparameters\n",
        "cartpole_hyperparameters = {\n",
        "    \"h_size\": 16,\n",
        "    \"n_training_episodes\": 1000,\n",
        "    \"n_evaluation_episodes\": 10,\n",
        "    \"max_t\": 1000,\n",
        "    \"gamma\": 1.0,\n",
        "    \"lr\": 0.01,\n",
        "    \"env_id\": 'CartPole-v1',\n",
        "    \"state_space\": 4,\n",
        "    \"action_space\": 2,\n",
        "}\n",
        "\n",
        "# 2. Create environment\n",
        "env = gym.make(cartpole_hyperparameters['env_id'])\n",
        "\n",
        "# 3. Create policy network\n",
        "cartpole_policy = Policy(cartpole_hyperparameters['state_space'],\n",
        "                         cartpole_hyperparameters['h_size'],\n",
        "                         cartpole_hyperparameters['action_space']).to(device)\n",
        "\n",
        "# 4. Create optimizer\n",
        "optimizer = torch.optim.Adam(cartpole_policy.parameters(),\n",
        "                             lr = cartpole_hyperparameters['lr'])\n",
        "\n",
        "# 5. Training loop\n",
        "scores = reinforce(policy = cartpole_policy,\n",
        "                   optimizer = optimizer,\n",
        "                   env = env,\n",
        "                   n_episodes = cartpole_hyperparameters['n_training_episodes'],\n",
        "                   n_steps = cartpole_hyperparameters['max_t'],\n",
        "                   device = device,\n",
        "                   gamma = cartpole_hyperparameters['gamma'],\n",
        "                   print_every = 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxfzmD1qgezs"
      },
      "source": [
        "## 4. Evaluate the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv8UUFpONyop"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(n_eval_episodes, n_steps, policy, env, device):\n",
        "\n",
        "  \"\"\"\n",
        "  Evaluate the performance of an agent by calculating the mean and standard deviation rewards over n_eval_episodes of episodes.\n",
        "\n",
        "  Args:\n",
        "    n_eval_episodes (int): Number of evaluation episodes. \\n\n",
        "    n_steps (int): Maximum number of steps allowed in an episode. \\n\n",
        "    policy (nn.Module): A policy network. \\n\n",
        "    env (gymnasium.env): An environment. \\n\n",
        "    device (str): 'cuda' or 'cpu'. \\n\n",
        "\n",
        "  Returns:\n",
        "    mean_reward (float): Mean reward scored across the evaluated episodes.\n",
        "    std_reward (float): Standard deviation reward scored across the evaluated episodes.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  rewards_across_episodes = [] # Contains rewards scored in each episode\n",
        "\n",
        "  ####################\n",
        "  # For each episode #\n",
        "  ####################\n",
        "  for episode in range(n_eval_episodes):\n",
        "\n",
        "    # To store reward scored in each step\n",
        "    rewards = []\n",
        "\n",
        "    # Reset the environment\n",
        "    state, info = env.reset()\n",
        "\n",
        "    #################\n",
        "    # For each step #\n",
        "    #################\n",
        "    for step in range(n_steps):\n",
        "\n",
        "      # Sample an action\n",
        "      action, _ = policy.act(torch.tensor(state).unsqueeze(0).to(device))\n",
        "\n",
        "      # Step the environment by taking the action\n",
        "      state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "      # Store the reward scored in this step\n",
        "      rewards.append(reward)\n",
        "\n",
        "      # Check if truncated or terminated\n",
        "      if truncated or terminated:\n",
        "        break\n",
        "\n",
        "    # Sum the reward scored in the entire episode and store it\n",
        "    rewards_across_episodes.append(sum(rewards))\n",
        "\n",
        "  # Calculate the mean and standard deviation\n",
        "  mean_reward = np.array(rewards_across_episodes).mean()\n",
        "  std_reward = np.array(rewards_across_episodes).std()\n",
        "  return mean_reward, std_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxmjk5iPYuUk",
        "outputId": "41a9d76d-b64e-4cf0-ba19-6ffd239c0f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: 500.0, standard deviation: 0.0\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_agent(n_eval_episodes = cartpole_hyperparameters['n_evaluation_episodes'],\n",
        "                                         n_steps = cartpole_hyperparameters['max_t'],\n",
        "                                         policy = cartpole_policy,\n",
        "                                         env = env,\n",
        "                                         device = device)\n",
        "\n",
        "print(f\"Mean reward: {mean_reward}, standard deviation: {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kvncEYCXXAG"
      },
      "source": [
        "## 5. Push to Hub\n",
        "\n",
        "* Code source: https://colab.research.google.com/github/wengti/Reinforcement-Learning-Tutorial-/blob/main/notebooks/unit4/unit4.ipynb#scrollTo=LIVsvlW_8tcw\n",
        "\n",
        "* Creat a write token here:\n",
        "https://huggingface.co/settings/tokens/new?tokenType=write"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Uf4KNZgv7L"
      },
      "outputs": [],
      "source": [
        "def record_video(env, policy, out_directory, device, fps=30):\n",
        "  \"\"\"\n",
        "  Generate a replay video of the agent\n",
        "  :param env\n",
        "  :param Qtable: Qtable of our agent\n",
        "  :param out_directory\n",
        "  :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  state, info = env.reset()\n",
        "  terminated = False\n",
        "  truncated = False\n",
        "  img = env.render()\n",
        "  images.append(img)\n",
        "  while not terminated and not truncated:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _ = policy.act(torch.tensor(state).unsqueeze(0).to(device))\n",
        "    state, reward, terminated, truncated, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render()\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9ES68IlhCWs"
      },
      "outputs": [],
      "source": [
        "def push_to_hub(repo_id,\n",
        "                model,\n",
        "                hyperparameters,\n",
        "                eval_env,\n",
        "                video_fps=30\n",
        "                ):\n",
        "  \"\"\"\n",
        "  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "  This method does the complete pipeline:\n",
        "  - It evaluates the model\n",
        "  - It generates the model card\n",
        "  - It generates a replay video of the agent\n",
        "  - It pushes everything to the Hub\n",
        "\n",
        "  :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
        "  :param model: the pytorch model we want to save\n",
        "  :param hyperparameters: training hyperparameters\n",
        "  :param eval_env: evaluation environment\n",
        "  :param video_fps: how many frame per seconds to record our video replay\n",
        "  \"\"\"\n",
        "\n",
        "  _, repo_name = repo_id.split(\"/\")\n",
        "  api = HfApi()\n",
        "\n",
        "  # Step 1: Create the repo\n",
        "  repo_url = api.create_repo(\n",
        "        repo_id=repo_id,\n",
        "        exist_ok=True,\n",
        "  )\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    local_directory = Path(tmpdirname)\n",
        "\n",
        "    # Step 2: Save the model\n",
        "    torch.save(model, local_directory / \"model.pt\")\n",
        "\n",
        "    # Step 3: Save the hyperparameters to JSON\n",
        "    with open(local_directory / \"hyperparameters.json\", \"w\") as outfile:\n",
        "      json.dump(hyperparameters, outfile)\n",
        "\n",
        "    # Step 4: Evaluate the model and build JSON\n",
        "    mean_reward, std_reward = evaluate_agent(hyperparameters[\"n_evaluation_episodes\"],\n",
        "                                            hyperparameters[\"max_t\"],\n",
        "                                            model,\n",
        "                                            eval_env,\n",
        "                                            'cuda')\n",
        "    # Get datetime\n",
        "    eval_datetime = datetime.datetime.now()\n",
        "    eval_form_datetime = eval_datetime.isoformat()\n",
        "\n",
        "    evaluate_data = {\n",
        "          \"env_id\": hyperparameters[\"env_id\"],\n",
        "          \"mean_reward\": mean_reward,\n",
        "          \"n_evaluation_episodes\": hyperparameters[\"n_evaluation_episodes\"],\n",
        "          \"eval_datetime\": eval_form_datetime,\n",
        "    }\n",
        "\n",
        "    # Write a JSON file\n",
        "    with open(local_directory / \"results.json\", \"w\") as outfile:\n",
        "        json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 5: Create the model card\n",
        "    env_name = hyperparameters[\"env_id\"]\n",
        "    env_id = env_name\n",
        "\n",
        "    metadata = {}\n",
        "    metadata[\"tags\"] = [\n",
        "          env_name,\n",
        "          \"reinforce\",\n",
        "          \"reinforcement-learning\",\n",
        "          \"custom-implementation\",\n",
        "          \"deep-rl-class\"\n",
        "      ]\n",
        "\n",
        "    # Add metrics\n",
        "    eval = metadata_eval_result(\n",
        "        model_pretty_name=repo_name,\n",
        "        task_pretty_name=\"reinforcement-learning\",\n",
        "        task_id=\"reinforcement-learning\",\n",
        "        metrics_pretty_name=\"mean_reward\",\n",
        "        metrics_id=\"mean_reward\",\n",
        "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "        dataset_pretty_name=env_name,\n",
        "        dataset_id=env_name,\n",
        "      )\n",
        "\n",
        "    # Merges both dictionaries\n",
        "    metadata = {**metadata, **eval}\n",
        "\n",
        "    model_card = f\"\"\"\n",
        "  # **Reinforce** Agent playing **{env_id}**\n",
        "  This is a trained model of a **Reinforce** agent playing **{env_id}** .\n",
        "  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n",
        "  \"\"\"\n",
        "\n",
        "    readme_path = local_directory / \"README.md\"\n",
        "    readme = \"\"\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "          readme = f.read()\n",
        "    else:\n",
        "      readme = model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "    # Step 6: Record a video\n",
        "    video_path =  local_directory / \"replay.mp4\"\n",
        "    record_video(eval_env, model, video_path, 'cuda', video_fps)\n",
        "\n",
        "    # Step 7. Push everything to the Hub\n",
        "    api.upload_folder(\n",
        "          repo_id=repo_id,\n",
        "          folder_path=local_directory,\n",
        "          path_in_repo=\".\",\n",
        "    )\n",
        "\n",
        "    print(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2cca45998ffc45248b2f442d8699f222",
            "7f9d25f2507c444abf07a3d296b7f64e"
          ]
        },
        "id": "mwCXYV6FiNX0",
        "outputId": "e4064704-8921-4043-d9c9-9e87f13f58a8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cca45998ffc45248b2f442d8699f222",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Login to hugging face with a write token\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "1c887a8ad054490087bfa73a35dfb2e3",
            "6af73a60cdea4f79b26386e5f5cfa1bf",
            "89b0062f3b5e4f95923cae513db7dad1",
            "5af7ddc5a6eb4e34bcdf996c39d9e813",
            "bdf0609076974da29ed2c76ec89207c1",
            "200c25fcbe8a4cf7aa380c03d2506272",
            "a644ada63cd94b3b9ae58be5eb817de4",
            "dc1e7b8fedb04d9d80da774059bc7973",
            "90d3691937a745dc975716a2ba91c9fa",
            "119a8a30ee6e4064bc94b170a8cd3f17",
            "a2f7c081e475430fadaeabf7b6ff8f9a"
          ]
        },
        "id": "-24NL5X9h4G4",
        "outputId": "c928a611-23d1-4973-c592-4f5598e763f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c887a8ad054490087bfa73a35dfb2e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading...:   0%|          | 0.00/3.78k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your model is pushed to the Hub. You can view your model here: https://huggingface.co/wengti0608/Reinforce-Cartpole-v1-attempt2\n"
          ]
        }
      ],
      "source": [
        "# Create a new environment with render mode (needed for video recording)\n",
        "eval_env = gym.make(cartpole_hyperparameters['env_id'], render_mode = 'rgb_array')\n",
        "\n",
        "# Push to Hub\n",
        "push_to_hub(repo_id = \"wengti0608/Reinforce-Cartpole-v1-attempt2\",\n",
        "            model = cartpole_policy,\n",
        "            hyperparameters = cartpole_hyperparameters,\n",
        "            eval_env = eval_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFtdU9xVhk1B"
      },
      "source": [
        "# Practice: Application of Reinforce to play Continuous Mountain Car\n",
        "\n",
        "* Environment documentation: https://gymnasium.farama.org/environments/classic_control/mountain_car/\n",
        "\n",
        "* Continuous Mountain Car agent takes continuous actions. Therefore, the policy network is slightly modified to output mean and standard deviation instead of index of discrete actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEvkC9i68X9y"
      },
      "source": [
        "## 0. Visualize Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Jziz80hkcK",
        "outputId": "092728ba-be51-42c4-be05-a6a24fdc9539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly sample an action: [0.9539736]\n",
            "Randomly sample a state: [-0.00267963 -0.00615319]\n"
          ]
        }
      ],
      "source": [
        "# Visualize the environment\n",
        "\n",
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "\n",
        "print(f\"Randomly sample an action: {env.action_space.sample()}\")\n",
        "print(f\"Randomly sample a state: {env.observation_space.sample()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWkoGN2Y8mBR"
      },
      "source": [
        "## 1. Create the policy network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sPzC4yZJvd6p"
      },
      "outputs": [],
      "source": [
        "class Policy(nn.Module):\n",
        "  \"\"\"\n",
        "  A policy network.\n",
        "\n",
        "  Args:\n",
        "    s_size (int): The size of 1 state space. \\n\n",
        "    h_size (int): The number of hidden nodes in the network. \\n\n",
        "    a_size (int): Number of continuos actions. \\n\n",
        "  \"\"\"\n",
        "  def __init__(self, s_size, h_size, a_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Sequential(nn.Linear(in_features = s_size,\n",
        "                                       out_features = h_size),\n",
        "                             nn.ReLU())\n",
        "\n",
        "    self.fc2 = nn.Sequential(nn.Linear(in_features = h_size,\n",
        "                                       out_features = h_size),\n",
        "                             nn.ReLU())\n",
        "\n",
        "    self.mean_head = nn.Linear(in_features = h_size,\n",
        "                               out_features = a_size)\n",
        "\n",
        "    self.log_std_head = nn.Linear(in_features = h_size,\n",
        "                                  out_features = a_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    The forward propagation of the policy network.\n",
        "\n",
        "    Args:\n",
        "      x (float tensor): Input to the network representing the observation / state, expected shape: (B, s_size). \\n\n",
        "\n",
        "    Returns:\n",
        "      mean (float tensor): Mean of a Normal Distribution, (B, a_size). \\n\n",
        "      std (float tensor): Standard deviation of a Normal Distribtuion, (B, a_size). \\n\n",
        "    \"\"\"\n",
        "    out = self.fc1(x)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    mean = self.mean_head(out)\n",
        "    log_std = self.log_std_head(out)\n",
        "    std = torch.exp(log_std)\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "  def act(self, state):\n",
        "    \"\"\"\n",
        "    Sampling of an action.\n",
        "\n",
        "    Args:\n",
        "      state (float tensor): Input to the network representing the observation / state, expected shape: (B, s_size). \\n\n",
        "\n",
        "    Returns:\n",
        "      action_clipped (float): The value of the action taken, in the range of -1 to 1 \\n\n",
        "      log_prob (float tensor): The ln of the probability of the action that was sampled based on the output probability of the newtork. \\n\n",
        "\n",
        "    \"\"\"\n",
        "    mean, std = self.forward(state)\n",
        "    mean = mean.cpu() # torch.tensor, (1,1)\n",
        "    std = std.cpu() # torch.tensor, (1,1)\n",
        "\n",
        "    m = Normal(mean, std)\n",
        "\n",
        "    action = m.sample() # torch.tensor, (1,1)\n",
        "    action_clipped = torch.clamp(action, -1, 1).item() #float\n",
        "\n",
        "    log_prob = m.log_prob(action)[0] # torch.tensor, (1,)\n",
        "\n",
        "    return action_clipped, log_prob\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUgjJ3Z8rWq"
      },
      "source": [
        "## 2. Implement reinforce algorithm from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "glmlqT4iyOeD"
      },
      "outputs": [],
      "source": [
        " def reinforce(policy, optimizer, env, n_episodes, n_steps, device, gamma, print_every):\n",
        "\n",
        "  \"\"\"\n",
        "  Train a policy network using the reinforce algorithm.\n",
        "\n",
        "  Args:\n",
        "    policy (nn.Module): A policy network. \\n\n",
        "    optimizer (torch.optim): An optimizer. \\n\n",
        "    env (gymnasium.env): An environment. \\n\n",
        "    n_episodes (int): Number of training episodes. \\n\n",
        "    n_steps (int): Maximum number of steps allowed in an episode. \\n\n",
        "    device (str): 'cuda' or 'cpu'\n",
        "    gamma (float): A discount factor, range from 0 to 1.\n",
        "    print_every (int): Number of episode intervals to print the performance of the network. \\n\n",
        "\n",
        "  Returns:\n",
        "    scores (list): A list of integer, each element representing the rewards scored in an episode. \\n\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Create variables to store the rewards scored for every episode\n",
        "  scores = []\n",
        "\n",
        "  # This variable store up to rewards scored for every episode up to \"print_every\" episodes\n",
        "  scores_deque = deque(maxlen = print_every)\n",
        "  len_deque = deque(maxlen = print_every)\n",
        "\n",
        "\n",
        "  ####################\n",
        "  # For each episode #\n",
        "  ####################\n",
        "  for episode in range(1, n_episodes+1):\n",
        "\n",
        "    # Variable to store values for every step within an episode\n",
        "    reward_eps = [] # Reward scored by each step\n",
        "    log_prob_eps = [] # ln (prob of the action taken) for each step\n",
        "    returns_eps = deque(maxlen = n_steps) # discounted returns scored in each step\n",
        "    policy_loss_eps = [] # loss for each step -> ln (prob of the action taken) * discounted return\n",
        "\n",
        "    # Reset the environment for the beginning of each episode\n",
        "    state, info = env.reset()\n",
        "\n",
        "    #################\n",
        "    # For each step #\n",
        "    #################\n",
        "    for _ in range(n_steps):\n",
        "\n",
        "      # Sample an action using the policy network\n",
        "      action, log_prob = policy.act(torch.tensor(state).unsqueeze(0).to(device))\n",
        "\n",
        "      # Step the environment using the sampled action\n",
        "      state, reward, terminated, truncated, info = env.step(np.array([action]))\n",
        "\n",
        "      # Store the rewards for this step and the ln (prob of this action)\n",
        "      reward_eps.append(reward)\n",
        "      log_prob_eps.append(log_prob)\n",
        "\n",
        "      # Check if this leads to termination or truncation\n",
        "      if terminated or truncated:\n",
        "        break\n",
        "\n",
        "    # Sum the rewards scored for the entire episode and store them\n",
        "    scores.append(sum(reward_eps))\n",
        "    scores_deque.append(sum(reward_eps))\n",
        "    len_deque.append(len(reward_eps))\n",
        "\n",
        "    # Calculate the discounted returns\n",
        "    for t in range(len(reward_eps))[::-1]:\n",
        "      returns = reward_eps[t] + gamma * returns_eps[0] if len(returns_eps) > 0 else reward_eps[t]\n",
        "      returns_eps.appendleft(returns)\n",
        "\n",
        "    # Normalize the discounted returns\n",
        "    eps = np.finfo(np.float32).eps.item() # eps is smallest reprsentatable float\n",
        "    returns_eps = torch.tensor(returns_eps) # Convert into torch tensor for later calculation\n",
        "    returns_eps = (returns_eps - returns_eps.mean()) / (returns_eps.std() + eps)\n",
        "\n",
        "    # Calculate the loss\n",
        "    for log_prob, returns in zip(log_prob_eps, returns_eps):\n",
        "      policy_loss_eps.append(-log_prob * returns) # torch tensor * torch tensor\n",
        "    loss = torch.cat(policy_loss_eps).sum() # cat -> makes into one torch tensor, sum() -> summation\n",
        "\n",
        "    # Backward propagation and gradient descent\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print information\n",
        "    if episode % print_every == 0:\n",
        "      print(f\"Current Episode: {episode} | Average reward: {np.mean(scores_deque)} | Average length of ep: {np.mean(len_deque)}\")\n",
        "\n",
        "  return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciSwfyT78u7w"
      },
      "source": [
        "## 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "HTdneJvSovKl",
        "outputId": "b2575e31-0424-490b-cf6f-123dda7e6e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Episode: 100 | Average reward: -50.15635252190986 | Average length of ep: 989.89\n",
            "Current Episode: 200 | Average reward: -52.40658396526536 | Average length of ep: 999.0\n",
            "Current Episode: 300 | Average reward: -46.566355785735915 | Average length of ep: 987.22\n",
            "Current Episode: 400 | Average reward: -48.63744804641728 | Average length of ep: 997.12\n",
            "Current Episode: 500 | Average reward: -47.35545788453662 | Average length of ep: 998.88\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2398987230>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                              lr = car_hyperparameters['lr'])\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m scores = reinforce(policy = car_policy,\n\u001b[0m\u001b[1;32m     30\u001b[0m                    \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                    \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2028213957>\u001b[0m in \u001b[0;36mreinforce\u001b[0;34m(policy, optimizer, env, n_episodes, n_steps, device, gamma, print_every)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m      \u001b[0;31m# Sample an action using the policy network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m      \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m      \u001b[0;31m# Step the environment using the sampled action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3619914407>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.tensor, (1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.tensor, (1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     53\u001b[0m         ]\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_VF.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 0. Device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 1. Hyperparameters\n",
        "car_hyperparameters = {\n",
        "    \"h_size\": 64,\n",
        "    \"n_training_episodes\": 2000,\n",
        "    \"n_evaluation_episodes\": 10,\n",
        "    \"max_t\": 999,\n",
        "    \"gamma\": 0.9,\n",
        "    \"lr\": 0.00001,\n",
        "    \"env_id\": 'MountainCarContinuous-v0',\n",
        "    \"state_space\": 2,\n",
        "    \"action_space\": 1,\n",
        "}\n",
        "\n",
        "# 2. Build a Policy Network\n",
        "car_policy = Policy(car_hyperparameters['state_space'],\n",
        "                    car_hyperparameters['h_size'],\n",
        "                    car_hyperparameters['action_space']).to(device)\n",
        "\n",
        "# 3. Create environment\n",
        "env = gym.make(car_hyperparameters['env_id'])\n",
        "\n",
        "# 4. Train the network\n",
        "optimizer = torch.optim.Adam(car_policy.parameters(),\n",
        "                             lr = car_hyperparameters['lr'])\n",
        "\n",
        "scores = reinforce(policy = car_policy,\n",
        "                   optimizer = optimizer,\n",
        "                   env = env,\n",
        "                   n_episodes = car_hyperparameters['n_training_episodes'],\n",
        "                   n_steps = car_hyperparameters['max_t'],\n",
        "                   device = device,\n",
        "                   gamma = car_hyperparameters['gamma'],\n",
        "                   print_every = 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQyKQ08R8x7m"
      },
      "source": [
        "## 4. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NqvN9mtO62vm"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(n_eval_episodes, n_steps, policy, env, device):\n",
        "\n",
        "  \"\"\"\n",
        "  Evaluate the performance of an agent by calculating the mean and standard deviation rewards over n_eval_episodes of episodes.\n",
        "\n",
        "  Args:\n",
        "    n_eval_episodes (int): Number of evaluation episodes. \\n\n",
        "    n_steps (int): Maximum number of steps allowed in an episode. \\n\n",
        "    policy (nn.Module): A policy network. \\n\n",
        "    env (gymnasium.env): An environment. \\n\n",
        "    device (str): 'cuda' or 'cpu'. \\n\n",
        "\n",
        "  Returns:\n",
        "    mean_reward (float): Mean reward scored across the evaluated episodes.\n",
        "    std_reward (float): Standard deviation reward scored across the evaluated episodes.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  rewards_across_episodes = [] # Contains rewards scored in each episode\n",
        "\n",
        "  ####################\n",
        "  # For each episode #\n",
        "  ####################\n",
        "  for episode in range(n_eval_episodes):\n",
        "\n",
        "    # To store reward scored in each step\n",
        "    rewards = []\n",
        "\n",
        "    # Reset the environment\n",
        "    state, info = env.reset()\n",
        "\n",
        "    #################\n",
        "    # For each step #\n",
        "    #################\n",
        "    for step in range(n_steps):\n",
        "\n",
        "      # Sample an action\n",
        "      action, _ = policy.act(torch.tensor(state).unsqueeze(0).to(device))\n",
        "\n",
        "      # Step the environment by taking the action\n",
        "      state, reward, terminated, truncated, info = env.step(np.array([action]))\n",
        "\n",
        "      # Store the reward scored in this step\n",
        "      rewards.append(reward)\n",
        "\n",
        "      # Check if truncated or terminated\n",
        "      if truncated or terminated:\n",
        "        break\n",
        "\n",
        "    # Sum the reward scored in the entire episode and store it\n",
        "    rewards_across_episodes.append(sum(rewards))\n",
        "\n",
        "  # Calculate the mean and standard deviation\n",
        "  mean_reward = np.array(rewards_across_episodes).mean()\n",
        "  std_reward = np.array(rewards_across_episodes).std()\n",
        "  return mean_reward, std_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T66aEK4c7Quc",
        "outputId": "493c553f-491c-483a-8ac2-cc211f3fbb63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -46.63831101175287, Std reward: 1.2278728245384134\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_agent(n_eval_episodes = car_hyperparameters['n_evaluation_episodes'],\n",
        "                                         n_steps = car_hyperparameters['max_t'],\n",
        "                                         policy = car_policy,\n",
        "                                         env = env,\n",
        "                                         device = device)\n",
        "\n",
        "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K42RCUkD80fN"
      },
      "source": [
        "## 5. Push to Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk9S-DRN7-Hp"
      },
      "outputs": [],
      "source": [
        "def record_video(env, policy, out_directory, device, fps=30):\n",
        "  \"\"\"\n",
        "  Generate a replay video of the agent\n",
        "  :param env\n",
        "  :param Qtable: Qtable of our agent\n",
        "  :param out_directory\n",
        "  :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  state, info = env.reset()\n",
        "  terminated = False\n",
        "  truncated = False\n",
        "  img = env.render()\n",
        "  images.append(img)\n",
        "  while not terminated and not truncated:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _ = policy.act(torch.tensor(state).unsqueeze(0).to(device))\n",
        "    state, reward, terminated, truncated, info = env.step(np.array([action])) # We directly put next_state = state for recording logic\n",
        "    img = env.render()\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9783fWZo7PbG"
      },
      "outputs": [],
      "source": [
        "def push_to_hub(repo_id,\n",
        "                model,\n",
        "                hyperparameters,\n",
        "                eval_env,\n",
        "                video_fps=30\n",
        "                ):\n",
        "  \"\"\"\n",
        "  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "  This method does the complete pipeline:\n",
        "  - It evaluates the model\n",
        "  - It generates the model card\n",
        "  - It generates a replay video of the agent\n",
        "  - It pushes everything to the Hub\n",
        "\n",
        "  :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
        "  :param model: the pytorch model we want to save\n",
        "  :param hyperparameters: training hyperparameters\n",
        "  :param eval_env: evaluation environment\n",
        "  :param video_fps: how many frame per seconds to record our video replay\n",
        "  \"\"\"\n",
        "\n",
        "  _, repo_name = repo_id.split(\"/\")\n",
        "  api = HfApi()\n",
        "\n",
        "  # Step 1: Create the repo\n",
        "  repo_url = api.create_repo(\n",
        "        repo_id=repo_id,\n",
        "        exist_ok=True,\n",
        "  )\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    local_directory = Path(tmpdirname)\n",
        "\n",
        "    # Step 2: Save the model\n",
        "    torch.save(model, local_directory / \"model.pt\")\n",
        "\n",
        "    # Step 3: Save the hyperparameters to JSON\n",
        "    with open(local_directory / \"hyperparameters.json\", \"w\") as outfile:\n",
        "      json.dump(hyperparameters, outfile)\n",
        "\n",
        "    # Step 4: Evaluate the model and build JSON\n",
        "    mean_reward, std_reward = evaluate_agent(hyperparameters[\"n_evaluation_episodes\"],\n",
        "                                            hyperparameters[\"max_t\"],\n",
        "                                            model,\n",
        "                                            eval_env,\n",
        "                                            'cuda')\n",
        "    # Get datetime\n",
        "    eval_datetime = datetime.datetime.now()\n",
        "    eval_form_datetime = eval_datetime.isoformat()\n",
        "\n",
        "    evaluate_data = {\n",
        "          \"env_id\": hyperparameters[\"env_id\"],\n",
        "          \"mean_reward\": mean_reward,\n",
        "          \"n_evaluation_episodes\": hyperparameters[\"n_evaluation_episodes\"],\n",
        "          \"eval_datetime\": eval_form_datetime,\n",
        "    }\n",
        "\n",
        "    # Write a JSON file\n",
        "    with open(local_directory / \"results.json\", \"w\") as outfile:\n",
        "        json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 5: Create the model card\n",
        "    env_name = hyperparameters[\"env_id\"]\n",
        "    env_id = env_name\n",
        "\n",
        "    metadata = {}\n",
        "    metadata[\"tags\"] = [\n",
        "          env_name,\n",
        "          \"reinforce\",\n",
        "          \"reinforcement-learning\",\n",
        "          \"custom-implementation\",\n",
        "          \"deep-rl-class\"\n",
        "      ]\n",
        "\n",
        "    # Add metrics\n",
        "    eval = metadata_eval_result(\n",
        "        model_pretty_name=repo_name,\n",
        "        task_pretty_name=\"reinforcement-learning\",\n",
        "        task_id=\"reinforcement-learning\",\n",
        "        metrics_pretty_name=\"mean_reward\",\n",
        "        metrics_id=\"mean_reward\",\n",
        "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "        dataset_pretty_name=env_name,\n",
        "        dataset_id=env_name,\n",
        "      )\n",
        "\n",
        "    # Merges both dictionaries\n",
        "    metadata = {**metadata, **eval}\n",
        "\n",
        "    model_card = f\"\"\"\n",
        "  # **Reinforce** Agent playing **{env_id}**\n",
        "  This is a trained model of a **Reinforce** agent playing **{env_id}** .\n",
        "  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n",
        "  \"\"\"\n",
        "\n",
        "    readme_path = local_directory / \"README.md\"\n",
        "    readme = \"\"\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "          readme = f.read()\n",
        "    else:\n",
        "      readme = model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "    # Step 6: Record a video\n",
        "    video_path =  local_directory / \"replay.mp4\"\n",
        "    record_video(eval_env, model, video_path, 'cuda', video_fps)\n",
        "\n",
        "    # Step 7. Push everything to the Hub\n",
        "    api.upload_folder(\n",
        "          repo_id=repo_id,\n",
        "          folder_path=local_directory,\n",
        "          path_in_repo=\".\",\n",
        "    )\n",
        "\n",
        "    print(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWYQi9lJutl-"
      },
      "outputs": [],
      "source": [
        "# Login to HuggingFace Hub\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "c27e38fbe0a64200ae1b1df44ce8f3c4",
            "eb64da3a80b2403486e677031b8609f1",
            "b507737709f944e1b615ac4a6fc8f006",
            "00ef25b5c2074b3fbe47db643a35d291",
            "00cda4ef5d9144a8894aa7175652c55e",
            "9118c7c27e7b4b24a9c8ef5407574d3b",
            "0ed0cdf7bc4c4620bd07f59ecab65b06",
            "df5b378a55024b4b8a8c48668e9b19b1",
            "1cb18a92188f4287b56b822464e0c774",
            "464298f0f6594cc8b2580ffe28387011",
            "cac6afe707e14c22b8ba9118fe77cc2b"
          ]
        },
        "id": "Sls0ihZ9uSgZ",
        "outputId": "9d825aca-5077-4b2b-9ae2-6a4eedf39b53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c27e38fbe0a64200ae1b1df44ce8f3c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading...:   0%|          | 0.00/127k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your model is pushed to the Hub. You can view your model here: https://huggingface.co/wengti0608/Reinforce-MountainCarContinuous-v0-attempt1\n"
          ]
        }
      ],
      "source": [
        "# Create an evaluation environment\n",
        "eval_env = gym.make(car_hyperparameters['env_id'], render_mode = 'rgb_array')\n",
        "\n",
        "# Push to Hub\n",
        "push_to_hub(repo_id = \"wengti0608/Reinforce-MountainCarContinuous-v0-attempt1\",\n",
        "            model = car_policy,\n",
        "            hyperparameters = car_hyperparameters,\n",
        "            eval_env = eval_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving Mountain Car with SAC\n",
        "\n",
        "* Reinforce did not manage to solve Continuous Mountain Car. Therefore, SAC is used instead."
      ],
      "metadata": {
        "id": "VSH5sOdsYcEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3==2.0.0a5"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhwO-ulBaNoW",
        "outputId": "29851e4d-abd2-4b94-c931-807e62192138"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3==2.0.0a5 in /usr/local/lib/python3.11/dist-packages (2.0.0a5)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.0.0a5) (3.10.0)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->stable-baselines3==2.0.0a5) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.0.0a5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.0.0a5) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a5) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a5) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_sb3"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NDnxfaexFaJ",
        "outputId": "857ea8df-2752-4202-fb97-e02f2b17a25e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_sb3\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (0.33.0)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (6.0.2)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (1.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.6 in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2025.4.26)\n",
            "Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Installing collected packages: huggingface_sb3\n",
            "Successfully installed huggingface_sb3-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Training"
      ],
      "metadata": {
        "id": "AEqlF_0Cvzyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3.sac import SAC\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "\n",
        "# 1. Make environment\n",
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "\n",
        "# 2. Create a SAC model\n",
        "\n",
        "# The hyperparameter is provided here:\n",
        "# https://huggingface.co/sb3/sac-MountainCarContinuous-v0\n",
        "policy_kwargs = {'log_std_init': -3.67,\n",
        "                 'net_arch': [64, 64]}\n",
        "\n",
        "model = SAC(batch_size = 512,\n",
        "            buffer_size = 50000,\n",
        "            ent_coef = 0.1,\n",
        "            gamma = 0.9999,\n",
        "            gradient_steps = 32,\n",
        "            learning_rate = 0.0003,\n",
        "            learning_starts = 0,\n",
        "            policy = 'MlpPolicy',\n",
        "            policy_kwargs = policy_kwargs,\n",
        "            tau = 0.01,\n",
        "            train_freq = 32,\n",
        "            use_sde = True,\n",
        "            env = env)\n",
        "\n",
        "# 3. Train the model\n",
        "\n",
        "# As SAC does not output rollout on its own\n",
        "# A callback is manually created...\n",
        "eval_env = Monitor(gym.make(\"MountainCarContinuous-v0\", render_mode = \"rgb_array\"))\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path = './logs/SAC',\n",
        "    log_path = './logs/SAC',\n",
        "    eval_freq = 1e3,\n",
        "    deterministic = True,\n",
        "    render = False\n",
        ")\n",
        "\n",
        "# Training\n",
        "model.learn(total_timesteps = 5e4, callback = eval_callback)\n",
        "\n",
        "# 4. Save the model\n",
        "model_name = \"SAC-MountainCarContinuous-v0\"\n",
        "model.save(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iZN1IAKxYcjJ",
        "outputId": "2e454471-5cdb-4cbf-b308-0ae573af619b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=1000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 999.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=2000, episode_reward=-0.35 +/- 0.01\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=3000, episode_reward=-0.72 +/- 0.00\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=4000, episode_reward=-11.67 +/- 0.01\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=5000, episode_reward=-7.47 +/- 0.00\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=6000, episode_reward=-7.46 +/- 2.55\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=7000, episode_reward=-4.87 +/- 2.09\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=8000, episode_reward=-26.67 +/- 11.94\n",
            "Episode length: 999.00 +/- 0.00\n",
            "Eval num_timesteps=9000, episode_reward=39.76 +/- 38.70\n",
            "Episode length: 839.40 +/- 139.86\n",
            "New best mean reward!\n",
            "Eval num_timesteps=10000, episode_reward=62.72 +/- 5.42\n",
            "Episode length: 531.20 +/- 77.46\n",
            "New best mean reward!\n",
            "Eval num_timesteps=11000, episode_reward=57.76 +/- 14.58\n",
            "Episode length: 573.60 +/- 190.10\n",
            "Eval num_timesteps=12000, episode_reward=24.13 +/- 57.44\n",
            "Episode length: 663.80 +/- 265.59\n",
            "Eval num_timesteps=13000, episode_reward=58.75 +/- 19.28\n",
            "Episode length: 489.20 +/- 223.08\n",
            "Eval num_timesteps=14000, episode_reward=84.33 +/- 4.87\n",
            "Episode length: 226.60 +/- 69.47\n",
            "New best mean reward!\n",
            "Eval num_timesteps=15000, episode_reward=93.52 +/- 0.59\n",
            "Episode length: 143.00 +/- 12.66\n",
            "New best mean reward!\n",
            "Eval num_timesteps=16000, episode_reward=92.56 +/- 3.57\n",
            "Episode length: 115.60 +/- 51.70\n",
            "Eval num_timesteps=17000, episode_reward=92.80 +/- 1.42\n",
            "Episode length: 107.80 +/- 29.84\n",
            "Eval num_timesteps=18000, episode_reward=93.68 +/- 0.24\n",
            "Episode length: 90.40 +/- 5.95\n",
            "New best mean reward!\n",
            "Eval num_timesteps=19000, episode_reward=93.51 +/- 1.41\n",
            "Episode length: 101.40 +/- 29.49\n",
            "Eval num_timesteps=20000, episode_reward=93.23 +/- 1.28\n",
            "Episode length: 100.40 +/- 25.97\n",
            "Eval num_timesteps=21000, episode_reward=94.04 +/- 0.11\n",
            "Episode length: 83.00 +/- 3.41\n",
            "New best mean reward!\n",
            "Eval num_timesteps=22000, episode_reward=94.04 +/- 0.33\n",
            "Episode length: 85.60 +/- 6.56\n",
            "Eval num_timesteps=23000, episode_reward=93.76 +/- 0.18\n",
            "Episode length: 82.00 +/- 3.46\n",
            "Eval num_timesteps=24000, episode_reward=93.83 +/- 0.04\n",
            "Episode length: 77.40 +/- 0.80\n",
            "Eval num_timesteps=25000, episode_reward=93.52 +/- 0.10\n",
            "Episode length: 77.80 +/- 1.17\n",
            "Eval num_timesteps=26000, episode_reward=93.37 +/- 0.05\n",
            "Episode length: 78.60 +/- 0.49\n",
            "Eval num_timesteps=27000, episode_reward=93.52 +/- 0.02\n",
            "Episode length: 76.20 +/- 0.40\n",
            "Eval num_timesteps=28000, episode_reward=92.13 +/- 2.32\n",
            "Episode length: 91.00 +/- 27.00\n",
            "Eval num_timesteps=29000, episode_reward=89.84 +/- 2.95\n",
            "Episode length: 115.40 +/- 32.99\n",
            "Eval num_timesteps=30000, episode_reward=93.29 +/- 0.03\n",
            "Episode length: 75.80 +/- 0.40\n",
            "Eval num_timesteps=31000, episode_reward=93.46 +/- 0.02\n",
            "Episode length: 75.20 +/- 1.47\n",
            "Eval num_timesteps=32000, episode_reward=93.18 +/- 0.94\n",
            "Episode length: 78.80 +/- 10.17\n",
            "Eval num_timesteps=33000, episode_reward=92.36 +/- 1.11\n",
            "Episode length: 88.20 +/- 13.24\n",
            "Eval num_timesteps=34000, episode_reward=93.28 +/- 0.99\n",
            "Episode length: 79.20 +/- 10.09\n",
            "Eval num_timesteps=35000, episode_reward=93.67 +/- 0.06\n",
            "Episode length: 73.40 +/- 1.85\n",
            "Eval num_timesteps=36000, episode_reward=93.74 +/- 0.05\n",
            "Episode length: 72.40 +/- 0.49\n",
            "Eval num_timesteps=37000, episode_reward=92.87 +/- 1.30\n",
            "Episode length: 85.20 +/- 15.84\n",
            "Eval num_timesteps=38000, episode_reward=93.14 +/- 1.85\n",
            "Episode length: 85.60 +/- 14.31\n",
            "Eval num_timesteps=39000, episode_reward=94.56 +/- 0.07\n",
            "Episode length: 73.20 +/- 1.94\n",
            "New best mean reward!\n",
            "Eval num_timesteps=40000, episode_reward=94.43 +/- 0.24\n",
            "Episode length: 78.40 +/- 4.32\n",
            "Eval num_timesteps=41000, episode_reward=94.66 +/- 0.07\n",
            "Episode length: 75.60 +/- 1.50\n",
            "New best mean reward!\n",
            "Eval num_timesteps=42000, episode_reward=94.66 +/- 0.47\n",
            "Episode length: 78.00 +/- 7.51\n",
            "New best mean reward!\n",
            "Eval num_timesteps=43000, episode_reward=94.85 +/- 0.15\n",
            "Episode length: 74.40 +/- 3.20\n",
            "New best mean reward!\n",
            "Eval num_timesteps=44000, episode_reward=94.58 +/- 0.10\n",
            "Episode length: 75.20 +/- 1.72\n",
            "Eval num_timesteps=45000, episode_reward=94.57 +/- 0.06\n",
            "Episode length: 73.00 +/- 1.10\n",
            "Eval num_timesteps=46000, episode_reward=94.52 +/- 0.18\n",
            "Episode length: 74.40 +/- 3.83\n",
            "Eval num_timesteps=47000, episode_reward=94.68 +/- 0.16\n",
            "Episode length: 74.80 +/- 3.31\n",
            "Eval num_timesteps=48000, episode_reward=94.69 +/- 0.11\n",
            "Episode length: 73.20 +/- 1.60\n",
            "Eval num_timesteps=49000, episode_reward=94.80 +/- 0.07\n",
            "Episode length: 72.40 +/- 1.02\n",
            "Eval num_timesteps=50000, episode_reward=94.57 +/- 0.12\n",
            "Episode length: 75.00 +/- 1.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Evaluation"
      ],
      "metadata": {
        "id": "ZTRUibZQv3bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Create an evaluation environment\n",
        "eval_env = Monitor(gym.make(\"MountainCarContinuous-v0\", render_mode = \"rgb_array\"))\n",
        "\n",
        "#2. Evaluate policy\n",
        "mean_reward, std_reward = evaluate_policy(model = model,\n",
        "                                          env = eval_env,\n",
        "                                          n_eval_episodes = 10,\n",
        "                                          deterministic = True)\n",
        "\n",
        "print(f\"The mean reward: {mean_reward} | The standard deviation: {std_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PIuYMpkhR9Z",
        "outputId": "fdeff1d6-4cbc-4f74-bd3c-d5dfdb8824ef"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean reward: 94.67033819999999 | The standard deviation: 0.2572431881083725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Push to Hub"
      ],
      "metadata": {
        "id": "NyJ11Yhkvs5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "ebe12f27b9be4788bae45df3dc126d51",
            "b9efdf16eaf54cbbb693d27be9285029",
            "92959aaa73a849928b840f091c1c78db",
            "faa1773cefa04cdfb882a0ef6f983156",
            "32d9e97f38c94d038a93c5aa0d3a3090",
            "7607608ae667475fb572bfa494ec093f",
            "e470412fea044d48adbd3ec085422d69",
            "7af8ab95730a48b0b52c74bebf5e80ae",
            "729876fbe0fe462089db0badfa74aafa",
            "17e9e054811f40e3ace40369f4d16f37",
            "393d3c6cd1c64934afe0108e9e294d72",
            "ad0975123d1f44bea326671fcb91bb71",
            "cc81db9b0b7943178d8ffd69bdb2987e",
            "968abc7fe44e43bca57ed2d97a9e909a",
            "31317764926444b3aed3793e811390b8",
            "80d5fb331dc846bcbd5cdbebef0c6e5d",
            "0b8634c802c04b749bc4c0cd1aaa5729",
            "5dca0ee7736e45d58675e2b31028eae7",
            "3212798d08e84ba29148f2f879347bfd",
            "cc790e4d35d74eec9fb8d0b34d026bf7"
          ]
        },
        "id": "gsVHHSE2v4ts",
        "outputId": "0f81fdb1-8c91-47e1-9d1e-f4e63e162d4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebe12f27b9be4788bae45df3dc126d51"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from huggingface_sb3 import package_to_hub\n",
        "\n",
        "package_to_hub(model = model,\n",
        "               model_name = model_name,\n",
        "               model_architecture = \"SAC\",\n",
        "               env_id = \"MountainCarContinuous-v0\",\n",
        "               eval_env = DummyVecEnv([lambda: Monitor(gym.make(\"MountainCarContinuous-v0\", render_mode = \"rgb_array\"))]),\n",
        "               repo_id = \"wengti0608/SAC-MountainCarContinuous-v0\",\n",
        "               commit_message = \"First Commit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "1bb67d8ce21d45c7a9f7d2162369c3e6",
            "144e9eea07164b7286ba621f6fb25b34",
            "2e368a90aaec41bdae64c292a47595db",
            "dca694ad921a4dfe95a8cf50aa42d3dc",
            "5ee5aca4c75c44349b32738b5ab341e8",
            "031040e34f6a4e1599259e35f2f4baaf",
            "cc8afea7bfe74d11a2ed3864dc00154f",
            "0886de05a962419f97ec9efc32eee067",
            "0f620f0a91f84f4eb269350fb9453c23",
            "3e75b35c810e413db2937e5e11c1a8c4",
            "fcad7dc32c2344d292db0aba180ed074"
          ]
        },
        "collapsed": true,
        "id": "kNmjIeowwAAp",
        "outputId": "6741ce37-aa00-4af7-fec5-0aac2185cae6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to 1min.\n",
            "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video to /tmp/tmpycdvpsq5/-step-0-to-step-1000.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/moviepy/config_defaults.py:1: DeprecationWarning: invalid escape sequence '\\P'\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /tmp/tmpycdvpsq5/-step-0-to-step-1000.mp4.\n",
            "Moviepy - Writing video /tmp/tmpycdvpsq5/-step-0-to-step-1000.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /tmp/tmpycdvpsq5/-step-0-to-step-1000.mp4\n",
            "\u001b[38;5;4mℹ Pushing repo wengti0608/SAC-MountainCarContinuous-v0 to the Hugging\n",
            "Face Hub\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/668k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bb67d8ce21d45c7a9f7d2162369c3e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Your model is pushed to the Hub. You can view your model here:\n",
            "https://huggingface.co/wengti0608/SAC-MountainCarContinuous-v0/tree/main/\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/wengti0608/SAC-MountainCarContinuous-v0/commit/b687e03d8116617b1713a95102c5d82024fd64a3', commit_message='First Commit', commit_description='', oid='b687e03d8116617b1713a95102c5d82024fd64a3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/wengti0608/SAC-MountainCarContinuous-v0', endpoint='https://huggingface.co', repo_type='model', repo_id='wengti0608/SAC-MountainCarContinuous-v0'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPPXhBqKMMt60GdYn8JrcqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00cda4ef5d9144a8894aa7175652c55e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ef25b5c2074b3fbe47db643a35d291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464298f0f6594cc8b2580ffe28387011",
            "placeholder": "​",
            "style": "IPY_MODEL_cac6afe707e14c22b8ba9118fe77cc2b",
            "value": " 127k/127k [00:01&lt;00:00, 637kB/s]"
          }
        },
        "0ed0cdf7bc4c4620bd07f59ecab65b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "119a8a30ee6e4064bc94b170a8cd3f17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c887a8ad054490087bfa73a35dfb2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6af73a60cdea4f79b26386e5f5cfa1bf",
              "IPY_MODEL_89b0062f3b5e4f95923cae513db7dad1",
              "IPY_MODEL_5af7ddc5a6eb4e34bcdf996c39d9e813"
            ],
            "layout": "IPY_MODEL_bdf0609076974da29ed2c76ec89207c1"
          }
        },
        "1cb18a92188f4287b56b822464e0c774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "200c25fcbe8a4cf7aa380c03d2506272": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cca45998ffc45248b2f442d8699f222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_7f9d25f2507c444abf07a3d296b7f64e"
          }
        },
        "464298f0f6594cc8b2580ffe28387011": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af7ddc5a6eb4e34bcdf996c39d9e813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119a8a30ee6e4064bc94b170a8cd3f17",
            "placeholder": "​",
            "style": "IPY_MODEL_a2f7c081e475430fadaeabf7b6ff8f9a",
            "value": " 3.78k/3.78k [00:01&lt;00:00, 18.8kB/s]"
          }
        },
        "6af73a60cdea4f79b26386e5f5cfa1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_200c25fcbe8a4cf7aa380c03d2506272",
            "placeholder": "​",
            "style": "IPY_MODEL_a644ada63cd94b3b9ae58be5eb817de4",
            "value": "Uploading...: 100%"
          }
        },
        "7f9d25f2507c444abf07a3d296b7f64e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "89b0062f3b5e4f95923cae513db7dad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc1e7b8fedb04d9d80da774059bc7973",
            "max": 3776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90d3691937a745dc975716a2ba91c9fa",
            "value": 3776
          }
        },
        "90d3691937a745dc975716a2ba91c9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9118c7c27e7b4b24a9c8ef5407574d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f7c081e475430fadaeabf7b6ff8f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a644ada63cd94b3b9ae58be5eb817de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b507737709f944e1b615ac4a6fc8f006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df5b378a55024b4b8a8c48668e9b19b1",
            "max": 126759,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cb18a92188f4287b56b822464e0c774",
            "value": 126759
          }
        },
        "bdf0609076974da29ed2c76ec89207c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27e38fbe0a64200ae1b1df44ce8f3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb64da3a80b2403486e677031b8609f1",
              "IPY_MODEL_b507737709f944e1b615ac4a6fc8f006",
              "IPY_MODEL_00ef25b5c2074b3fbe47db643a35d291"
            ],
            "layout": "IPY_MODEL_00cda4ef5d9144a8894aa7175652c55e"
          }
        },
        "cac6afe707e14c22b8ba9118fe77cc2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc1e7b8fedb04d9d80da774059bc7973": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df5b378a55024b4b8a8c48668e9b19b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb64da3a80b2403486e677031b8609f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9118c7c27e7b4b24a9c8ef5407574d3b",
            "placeholder": "​",
            "style": "IPY_MODEL_0ed0cdf7bc4c4620bd07f59ecab65b06",
            "value": "Uploading...: 100%"
          }
        },
        "ebe12f27b9be4788bae45df3dc126d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_e470412fea044d48adbd3ec085422d69"
          }
        },
        "b9efdf16eaf54cbbb693d27be9285029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7af8ab95730a48b0b52c74bebf5e80ae",
            "placeholder": "​",
            "style": "IPY_MODEL_729876fbe0fe462089db0badfa74aafa",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "92959aaa73a849928b840f091c1c78db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_17e9e054811f40e3ace40369f4d16f37",
            "placeholder": "​",
            "style": "IPY_MODEL_393d3c6cd1c64934afe0108e9e294d72",
            "value": ""
          }
        },
        "faa1773cefa04cdfb882a0ef6f983156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_ad0975123d1f44bea326671fcb91bb71",
            "style": "IPY_MODEL_cc81db9b0b7943178d8ffd69bdb2987e",
            "value": true
          }
        },
        "32d9e97f38c94d038a93c5aa0d3a3090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_968abc7fe44e43bca57ed2d97a9e909a",
            "style": "IPY_MODEL_31317764926444b3aed3793e811390b8",
            "tooltip": ""
          }
        },
        "7607608ae667475fb572bfa494ec093f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d5fb331dc846bcbd5cdbebef0c6e5d",
            "placeholder": "​",
            "style": "IPY_MODEL_0b8634c802c04b749bc4c0cd1aaa5729",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e470412fea044d48adbd3ec085422d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7af8ab95730a48b0b52c74bebf5e80ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729876fbe0fe462089db0badfa74aafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e9e054811f40e3ace40369f4d16f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393d3c6cd1c64934afe0108e9e294d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad0975123d1f44bea326671fcb91bb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc81db9b0b7943178d8ffd69bdb2987e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968abc7fe44e43bca57ed2d97a9e909a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31317764926444b3aed3793e811390b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "80d5fb331dc846bcbd5cdbebef0c6e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8634c802c04b749bc4c0cd1aaa5729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dca0ee7736e45d58675e2b31028eae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3212798d08e84ba29148f2f879347bfd",
            "placeholder": "​",
            "style": "IPY_MODEL_cc790e4d35d74eec9fb8d0b34d026bf7",
            "value": "Connecting..."
          }
        },
        "3212798d08e84ba29148f2f879347bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc790e4d35d74eec9fb8d0b34d026bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bb67d8ce21d45c7a9f7d2162369c3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_144e9eea07164b7286ba621f6fb25b34",
              "IPY_MODEL_2e368a90aaec41bdae64c292a47595db",
              "IPY_MODEL_dca694ad921a4dfe95a8cf50aa42d3dc"
            ],
            "layout": "IPY_MODEL_5ee5aca4c75c44349b32738b5ab341e8"
          }
        },
        "144e9eea07164b7286ba621f6fb25b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_031040e34f6a4e1599259e35f2f4baaf",
            "placeholder": "​",
            "style": "IPY_MODEL_cc8afea7bfe74d11a2ed3864dc00154f",
            "value": "Uploading...: 100%"
          }
        },
        "2e368a90aaec41bdae64c292a47595db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0886de05a962419f97ec9efc32eee067",
            "max": 668067,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f620f0a91f84f4eb269350fb9453c23",
            "value": 668067
          }
        },
        "dca694ad921a4dfe95a8cf50aa42d3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e75b35c810e413db2937e5e11c1a8c4",
            "placeholder": "​",
            "style": "IPY_MODEL_fcad7dc32c2344d292db0aba180ed074",
            "value": " 668k/668k [00:01&lt;00:00, 3.09MB/s]"
          }
        },
        "5ee5aca4c75c44349b32738b5ab341e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031040e34f6a4e1599259e35f2f4baaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8afea7bfe74d11a2ed3864dc00154f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0886de05a962419f97ec9efc32eee067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f620f0a91f84f4eb269350fb9453c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e75b35c810e413db2937e5e11c1a8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcad7dc32c2344d292db0aba180ed074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}